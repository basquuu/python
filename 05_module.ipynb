{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1425da-4cc0-4e40-95df-5378fc068804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266cdd5c-345d-4542-9e74-34967c1e09c4",
   "metadata": {},
   "source": [
    "## random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e091fb30-ecb2-4e1e-a7a0-1c1f3a26122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96af7736-c806-4524-8557-05488b03342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052363598850944326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(123)\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3692d5b-13a1-408b-945a-539e595ace27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 2, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "random.shuffle(numbers)\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93295575-d56e-41a5-9ad0-f160d4907c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92c740c-a526-4e9f-b34d-558a94e69c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(numbers, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75768475-ba8e-42da-bcdf-005a3127b77e",
   "metadata": {},
   "source": [
    "## datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f769881-ecb8-4336-998f-ff01e147c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb538cf3-af8c-4696-9c18-90738cc9ff16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 7, 2, 10, 44, 43, 236510)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d270f32b-5e54-4095-8041-2fa363bfec13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 7, 2, 10, 53, 12, 529663)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b42811-7322-4492-85b1-ca1ee0f8f531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 7, 2, 1, 53, 16, 903844)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ffcf1e3-cb2e-4a5a-bfb7-7720ae6918a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-02 10:58:47.924855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2024년 07월 02일 Tue'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(now)\n",
    "now.strftime('%Y년 %m월 %d일 %a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33be264b-fb76-497b-b28c-3d0899e1a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "x_mas = datetime(2024,12,25)\n",
    "print(x_mas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a7608a0-c36b-4bf0-86c5-12515de15aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aac3022-dbe5-4d02-8cb7-4afa22562d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 days, 12:53:55.690690\n"
     ]
    }
   ],
   "source": [
    "new_year = datetime(2025, 1, 1)\n",
    "now = datetime.now()\n",
    "\n",
    "print(new_year - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db824714-3d87-4456-a9af-c8d2b34d27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-10 11:06:22.392581\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "d100 = timedelta(days=100)\n",
    "\n",
    "print(now+d100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922946b-94ba-47d0-957f-a86caac7f9e7",
   "metadata": {},
   "source": [
    "## requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c84292-d8a5-46c6-956f-b0c98937dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f4f1be-f6cf-4442-815c-38458fe34504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"id\":\"39785531639\",\"type\":\"PushEvent\",\"actor\":{\"id\":41898282,\"login\":\"github-actions[bot]\",\"display_login\":\"github-actions\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/github-actions[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/41898282?\"},\"repo\":{\"id\":443801098,\"name\":\"factcheckr/daum_factcheck\",\"url\":\"https://api.github.com/repos/factcheckr/daum_factcheck\"},\"payload\":{\"repository_id\":443801098,\"push_id\":19131669365,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/gh-pages\",\"head\":\"c2f66ec7a3558dbff1b66948d81d1c9d264c1c31\",\"before\":\"746c145c6565bba017a3af2c064c2d592313b126\",\"commits\":[{\"sha\":\"c2f66ec7a3558dbff1b66948d81d1c9d264c1c31\",\"author\":{\"email\":\"amblerkr@users.noreply.github.com\",\"name\":\"amblerkr\"},\"message\":\"Deploying to GitHub Pages from 89cee34520f5195ba6067da708619b25081a901f\",\"distinct\":true,\"url\":\"https://api.github.com/repos/factcheckr/daum_factcheck/commits/c2f66ec7a3558dbff1b66948d81d1c9d264c1c31\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\",\"org\":{\"id\":91438245,\"login\":\"factcheckr\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/factcheckr\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/91438245?\"}},{\"id\":\"39785531642\",\"type\":\"PushEvent\",\"actor\":{\"id\":41898282,\"login\":\"github-actions[bot]\",\"display_login\":\"github-actions\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/github-actions[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/41898282?\"},\"repo\":{\"id\":540359478,\"name\":\"ttaox34/TodoSync\",\"url\":\"https://api.github.com/repos/ttaox34/TodoSync\"},\"payload\":{\"repository_id\":540359478,\"push_id\":19131669369,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/graphtoken\",\"head\":\"5a62e7549e3d81933d1656e097b6bb3106828683\",\"before\":\"76e419744d3829b5f876e4c33dd66e18ef36d2f6\",\"commits\":[{\"sha\":\"5a62e7549e3d81933d1656e097b6bb3106828683\",\"author\":{\"email\":\"filestorage-action@users.noreply.github.com\",\"name\":\"filestorage-action\"},\"message\":\"update filestorage at 2024-07-02T02:37:07.511Z\",\"distinct\":true,\"url\":\"https://api.github.com/repos/ttaox34/TodoSync/commits/5a62e7549e3d81933d1656e097b6bb3106828683\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531648\",\"type\":\"CreateEvent\",\"actor\":{\"id\":79776489,\"login\":\"Fareeq1411\",\"display_login\":\"Fareeq1411\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/Fareeq1411\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/79776489?\"},\"repo\":{\"id\":822880012,\"name\":\"Fareeq1411/aleya\",\"url\":\"https://api.github.com/repos/Fareeq1411/aleya\"},\"payload\":{\"ref\":null,\"ref_type\":\"repository\",\"master_branch\":\"main\",\"description\":null,\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531640\",\"type\":\"PushEvent\",\"actor\":{\"id\":8218836,\"login\":\"jonathanlyonmoore\",\"display_login\":\"jonathanlyonmoore\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/jonathanlyonmoore\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/8218836?\"},\"repo\":{\"id\":818256165,\"name\":\"sphinxlogic/Santa-Cruz-Operation\",\"url\":\"https://api.github.com/repos/sphinxlogic/Santa-Cruz-Operation\"},\"payload\":{\"repository_id\":818256165,\"push_id\":19131669364,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"a1d0f375edd62cdb89e7a61bb2b98c86bd501cd0\",\"before\":\"4d422fbd2175ee4d6a276b7556d2aa0a9f2eac48\",\"commits\":[{\"sha\":\"a1d0f375edd62cdb89e7a61bb2b98c86bd501cd0\",\"author\":{\"email\":\"uxpc@microsoft.com\",\"name\":\"UXP Controls Automated Porting System\"},\"message\":\"updated readme\",\"distinct\":true,\"url\":\"https://api.github.com/repos/sphinxlogic/Santa-Cruz-Operation/commits/a1d0f375edd62cdb89e7a61bb2b98c86bd501cd0\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\",\"org\":{\"id\":171222846,\"login\":\"sphinxlogic\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/sphinxlogic\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/171222846?\"}},{\"id\":\"39785531630\",\"type\":\"CreateEvent\",\"actor\":{\"id\":49699333,\"login\":\"dependabot[bot]\",\"display_login\":\"dependabot\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/dependabot[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/49699333?\"},\"repo\":{\"id\":80172100,\"name\":\"kubernetes-sigs/cri-tools\",\"url\":\"https://api.github.com/repos/kubernetes-sigs/cri-tools\"},\"payload\":{\"ref\":\"dependabot/go_modules/github.com/docker/docker-27.0.3incompatible\",\"ref_type\":\"branch\",\"master_branch\":\"master\",\"description\":\"CLI and validation tools for Kubelet Container Runtime Interface (CRI) .\",\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\",\"org\":{\"id\":36015203,\"login\":\"kubernetes-sigs\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/kubernetes-sigs\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/36015203?\"}},{\"id\":\"39785531618\",\"type\":\"PullRequestEvent\",\"actor\":{\"id\":5965815,\"login\":\"digadeesh\",\"display_login\":\"digadeesh\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/digadeesh\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/5965815?\"},\"repo\":{\"id\":394089041,\"name\":\"spiceai/spiceai\",\"url\":\"https://api.github.com/repos/spiceai/spiceai\"},\"payload\":{\"action\":\"opened\",\"number\":1843,\"pull_request\":{\"url\":\"https://api.github.com/repos/spiceai/spiceai/pulls/1843\",\"id\":1948442169,\"node_id\":\"PR_kwDOF31SUc50It45\",\"html_url\":\"https://github.com/spiceai/spiceai/pull/1843\",\"diff_url\":\"https://github.com/spiceai/spiceai/pull/1843.diff\",\"patch_url\":\"https://github.com/spiceai/spiceai/pull/1843.patch\",\"issue_url\":\"https://api.github.com/repos/spiceai/spiceai/issues/1843\",\"number\":1843,\"state\":\"open\",\"locked\":false,\"title\":\"Update ROADMAP.md - Remove v0.15.0-alpha roadmap items.\",\"user\":{\"login\":\"digadeesh\",\"id\":5965815,\"node_id\":\"MDQ6VXNlcjU5NjU4MTU=\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/5965815?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/digadeesh\",\"html_url\":\"https://github.com/digadeesh\",\"followers_url\":\"https://api.github.com/users/digadeesh/followers\",\"following_url\":\"https://api.github.com/users/digadeesh/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/digadeesh/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/digadeesh/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/digadeesh/subscriptions\",\"organizations_url\":\"https://api.github.com/users/digadeesh/orgs\",\"repos_url\":\"https://api.github.com/users/digadeesh/repos\",\"events_url\":\"https://api.github.com/users/digadeesh/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/digadeesh/received_events\",\"type\":\"User\",\"site_admin\":false},\"body\":\"## 🗣 Description\\r\\n\\r\\nUpdating the roadmap per Endgame instructions.\\r\\n\\r\\n## 🔨 Related Issues\\r\\n\\r\\nN/A\\r\\n\",\"created_at\":\"2024-07-02T02:37:07Z\",\"updated_at\":\"2024-07-02T02:37:08Z\",\"closed_at\":null,\"merged_at\":null,\"merge_commit_sha\":null,\"assignee\":null,\"assignees\":[],\"requested_reviewers\":[],\"requested_teams\":[{\"name\":\"Spice Core Maintainers\",\"id\":5020817,\"node_id\":\"T_kwDOBGcOVs4ATJyR\",\"slug\":\"spice-core-maintainers\",\"description\":\"Maintainers of Spice AI Core\",\"privacy\":\"closed\",\"notification_setting\":\"notifications_enabled\",\"url\":\"https://api.github.com/organizations/73862742/team/5020817\",\"html_url\":\"https://github.com/orgs/spiceai/teams/spice-core-maintainers\",\"members_url\":\"https://api.github.com/organizations/73862742/team/5020817/members{/member}\",\"repositories_url\":\"https://api.github.com/organizations/73862742/team/5020817/repos\",\"permission\":\"pull\",\"parent\":null}],\"labels\":[],\"milestone\":null,\"draft\":false,\"commits_url\":\"https://api.github.com/repos/spiceai/spiceai/pulls/1843/commits\",\"review_comments_url\":\"https://api.github.com/repos/spiceai/spiceai/pulls/1843/comments\",\"review_comment_url\":\"https://api.github.com/repos/spiceai/spiceai/pulls/comments{/number}\",\"comments_url\":\"https://api.github.com/repos/spiceai/spiceai/issues/1843/comments\",\"statuses_url\":\"https://api.github.com/repos/spiceai/spiceai/statuses/f2cb013bbaa07d7ddae826e3192bae416336a528\",\"head\":{\"label\":\"spiceai:digadeesh-patch-3\",\"ref\":\"digadeesh-patch-3\",\"sha\":\"f2cb013bbaa07d7ddae826e3192bae416336a528\",\"user\":{\"login\":\"spiceai\",\"id\":73862742,\"node_id\":\"MDEyOk9yZ2FuaXphdGlvbjczODYyNzQy\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/73862742?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/spiceai\",\"html_url\":\"https://github.com/spiceai\",\"followers_url\":\"https://api.github.com/users/spiceai/followers\",\"following_url\":\"https://api.github.com/users/spiceai/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/spiceai/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/spiceai/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/spiceai/subscriptions\",\"organizations_url\":\"https://api.github.com/users/spiceai/orgs\",\"repos_url\":\"https://api.github.com/users/spiceai/repos\",\"events_url\":\"https://api.github.com/users/spiceai/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/spiceai/received_events\",\"type\":\"Organization\",\"site_admin\":false},\"repo\":{\"id\":394089041,\"node_id\":\"MDEwOlJlcG9zaXRvcnkzOTQwODkwNDE=\",\"name\":\"spiceai\",\"full_name\":\"spiceai/spiceai\",\"private\":false,\"owner\":{\"login\":\"spiceai\",\"id\":73862742,\"node_id\":\"MDEyOk9yZ2FuaXphdGlvbjczODYyNzQy\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/73862742?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/spiceai\",\"html_url\":\"https://github.com/spiceai\",\"followers_url\":\"https://api.github.com/users/spiceai/followers\",\"following_url\":\"https://api.github.com/users/spiceai/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/spiceai/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/spiceai/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/spiceai/subscriptions\",\"organizations_url\":\"https://api.github.com/users/spiceai/orgs\",\"repos_url\":\"https://api.github.com/users/spiceai/repos\",\"events_url\":\"https://api.github.com/users/spiceai/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/spiceai/received_events\",\"type\":\"Organization\",\"site_admin\":false},\"html_url\":\"https://github.com/spiceai/spiceai\",\"description\":\"A unified SQL query interface and portable runtime to locally materialize, accelerate, and query datasets from any database, data warehouse, or data lake.\",\"fork\":false,\"url\":\"https://api.github.com/repos/spiceai/spiceai\",\"forks_url\":\"https://api.github.com/repos/spiceai/spiceai/forks\",\"keys_url\":\"https://api.github.com/repos/spiceai/spiceai/keys{/key_id}\",\"collaborators_url\":\"https://api.github.com/repos/spiceai/spiceai/collaborators{/collaborator}\",\"teams_url\":\"https://api.github.com/repos/spiceai/spiceai/teams\",\"hooks_url\":\"https://api.github.com/repos/spiceai/spiceai/hooks\",\"issue_events_url\":\"https://api.github.com/repos/spiceai/spiceai/issues/events{/number}\",\"events_url\":\"https://api.github.com/repos/spiceai/spiceai/events\",\"assignees_url\":\"https://api.github.com/repos/spiceai/spiceai/assignees{/user}\",\"branches_url\":\"https://api.github.com/repos/spiceai/spiceai/branches{/branch}\",\"tags_url\":\"https://api.github.com/repos/spiceai/spiceai/tags\",\"blobs_url\":\"https://api.github.com/repos/spiceai/spiceai/git/blobs{/sha}\",\"git_tags_url\":\"https://api.github.com/repos/spiceai/spiceai/git/tags{/sha}\",\"git_refs_url\":\"https://api.github.com/repos/spiceai/spiceai/git/refs{/sha}\",\"trees_url\":\"https://api.github.com/repos/spiceai/spiceai/git/trees{/sha}\",\"statuses_url\":\"https://api.github.com/repos/spiceai/spiceai/statuses/{sha}\",\"languages_url\":\"https://api.github.com/repos/spiceai/spiceai/languages\",\"stargazers_url\":\"https://api.github.com/repos/spiceai/spiceai/stargazers\",\"contributors_url\":\"https://api.github.com/repos/spiceai/spiceai/contributors\",\"subscribers_url\":\"https://api.github.com/repos/spiceai/spiceai/subscribers\",\"subscription_url\":\"https://api.github.com/repos/spiceai/spiceai/subscription\",\"commits_url\":\"https://api.github.com/repos/spiceai/spiceai/commits{/sha}\",\"git_commits_url\":\"https://api.github.com/repos/spiceai/spiceai/git/commits{/sha}\",\"comments_url\":\"https://api.github.com/repos/spiceai/spiceai/comments{/number}\",\"issue_comment_url\":\"https://api.github.com/repos/spiceai/spiceai/issues/comments{/number}\",\"contents_url\":\"https://api.github.com/repos/spiceai/spiceai/contents/{+path}\",\"compare_url\":\"https://api.github.com/repos/spiceai/spiceai/compare/{base}...{head}\",\"merges_url\":\"https://api.github.com/repos/spiceai/spiceai/merges\",\"archive_url\":\"https://api.github.com/repos/spiceai/spiceai/{archive_format}{/ref}\",\"downloads_url\":\"https://api.github.com/repos/spiceai/spiceai/downloads\",\"issues_url\":\"https://api.github.com/repos/spiceai/spiceai/issues{/number}\",\"pulls_url\":\"https://api.github.com/repos/spiceai/spiceai/pulls{/number}\",\"milestones_url\":\"https://api.github.com/repos/spiceai/spiceai/milestones{/number}\",\"notifications_url\":\"https://api.github.com/repos/spiceai/spiceai/notifications{?since,all,participating}\",\"labels_url\":\"https://api.github.com/repos/spiceai/spiceai/labels{/name}\",\"releases_url\":\"https://api.github.com/repos/spiceai/spiceai/releases{/id}\",\"deployments_url\":\"https://api.github.com/repos/spiceai/spiceai/deployments\",\"created_at\":\"2021-08-08T23:26:13Z\",\"updated_at\":\"2024-07-02T00:43:42Z\",\"pushed_at\":\"2024-07-02T02:37:08Z\",\"git_url\":\"git://github.com/spiceai/spiceai.git\",\"ssh_url\":\"git@github.com:spiceai/spiceai.git\",\"clone_url\":\"https://github.com/spiceai/spiceai.git\",\"svn_url\":\"https://github.com/spiceai/spiceai\",\"homepage\":\"https://docs.spiceai.org\",\"size\":6762,\"stargazers_count\":1610,\"watchers_count\":1610,\"language\":\"Rust\",\"has_issues\":true,\"has_projects\":true,\"has_downloads\":true,\"has_wiki\":false,\"has_pages\":false,\"has_discussions\":false,\"forks_count\":66,\"mirror_url\":null,\"archived\":false,\"disabled\":false,\"open_issues_count\":68,\"license\":{\"key\":\"apache-2.0\",\"name\":\"Apache License 2.0\",\"spdx_id\":\"Apache-2.0\",\"url\":\"https://api.github.com/licenses/apache-2.0\",\"node_id\":\"MDc6TGljZW5zZTI=\"},\"allow_forking\":true,\"is_template\":false,\"web_commit_signoff_required\":false,\"topics\":[\"artificial-intelligence\",\"data\",\"developers\",\"infrastructure\",\"machine-learning\",\"sql\",\"time-series\"],\"visibility\":\"public\",\"forks\":66,\"open_issues\":68,\"watchers\":1610,\"default_branch\":\"trunk\"}},\"base\":{\"label\":\"spiceai:trunk\",\"ref\":\"trunk\",\"sha\":\"73286dd75ff292ce949741404f636679e9808d1a\",\"user\":{\"login\":\"spiceai\",\"id\":73862742,\"node_id\":\"MDEyOk9yZ2FuaXphdGlvbjczODYyNzQy\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/73862742?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/spiceai\",\"html_url\":\"https://github.com/spiceai\",\"followers_url\":\"https://api.github.com/users/spiceai/followers\",\"following_url\":\"https://api.github.com/users/spiceai/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/spiceai/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/spiceai/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/spiceai/subscriptions\",\"organizations_url\":\"https://api.github.com/users/spiceai/orgs\",\"repos_url\":\"https://api.github.com/users/spiceai/repos\",\"events_url\":\"https://api.github.com/users/spiceai/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/spiceai/received_events\",\"type\":\"Organization\",\"site_admin\":false},\"repo\":{\"id\":394089041,\"node_id\":\"MDEwOlJlcG9zaXRvcnkzOTQwODkwNDE=\",\"name\":\"spiceai\",\"full_name\":\"spiceai/spiceai\",\"private\":false,\"owner\":{\"login\":\"spiceai\",\"id\":73862742,\"node_id\":\"MDEyOk9yZ2FuaXphdGlvbjczODYyNzQy\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/73862742?v=4\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/spiceai\",\"html_url\":\"https://github.com/spiceai\",\"followers_url\":\"https://api.github.com/users/spiceai/followers\",\"following_url\":\"https://api.github.com/users/spiceai/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/spiceai/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/spiceai/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/spiceai/subscriptions\",\"organizations_url\":\"https://api.github.com/users/spiceai/orgs\",\"repos_url\":\"https://api.github.com/users/spiceai/repos\",\"events_url\":\"https://api.github.com/users/spiceai/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/spiceai/received_events\",\"type\":\"Organization\",\"site_admin\":false},\"html_url\":\"https://github.com/spiceai/spiceai\",\"description\":\"A unified SQL query interface and portable runtime to locally materialize, accelerate, and query datasets from any database, data warehouse, or data lake.\",\"fork\":false,\"url\":\"https://api.github.com/repos/spiceai/spiceai\",\"forks_url\":\"https://api.github.com/repos/spiceai/spiceai/forks\",\"keys_url\":\"https://api.github.com/repos/spiceai/spiceai/keys{/key_id}\",\"collaborators_url\":\"https://api.github.com/repos/spiceai/spiceai/collaborators{/collaborator}\",\"teams_url\":\"https://api.github.com/repos/spiceai/spiceai/teams\",\"hooks_url\":\"https://api.github.com/repos/spiceai/spiceai/hooks\",\"issue_events_url\":\"https://api.github.com/repos/spiceai/spiceai/issues/events{/number}\",\"events_url\":\"https://api.github.com/repos/spiceai/spiceai/events\",\"assignees_url\":\"https://api.github.com/repos/spiceai/spiceai/assignees{/user}\",\"branches_url\":\"https://api.github.com/repos/spiceai/spiceai/branches{/branch}\",\"tags_url\":\"https://api.github.com/repos/spiceai/spiceai/tags\",\"blobs_url\":\"https://api.github.com/repos/spiceai/spiceai/git/blobs{/sha}\",\"git_tags_url\":\"https://api.github.com/repos/spiceai/spiceai/git/tags{/sha}\",\"git_refs_url\":\"https://api.github.com/repos/spiceai/spiceai/git/refs{/sha}\",\"trees_url\":\"https://api.github.com/repos/spiceai/spiceai/git/trees{/sha}\",\"statuses_url\":\"https://api.github.com/repos/spiceai/spiceai/statuses/{sha}\",\"languages_url\":\"https://api.github.com/repos/spiceai/spiceai/languages\",\"stargazers_url\":\"https://api.github.com/repos/spiceai/spiceai/stargazers\",\"contributors_url\":\"https://api.github.com/repos/spiceai/spiceai/contributors\",\"subscribers_url\":\"https://api.github.com/repos/spiceai/spiceai/subscribers\",\"subscription_url\":\"https://api.github.com/repos/spiceai/spiceai/subscription\",\"commits_url\":\"https://api.github.com/repos/spiceai/spiceai/commits{/sha}\",\"git_commits_url\":\"https://api.github.com/repos/spiceai/spiceai/git/commits{/sha}\",\"comments_url\":\"https://api.github.com/repos/spiceai/spiceai/comments{/number}\",\"issue_comment_url\":\"https://api.github.com/repos/spiceai/spiceai/issues/comments{/number}\",\"contents_url\":\"https://api.github.com/repos/spiceai/spiceai/contents/{+path}\",\"compare_url\":\"https://api.github.com/repos/spiceai/spiceai/compare/{base}...{head}\",\"merges_url\":\"https://api.github.com/repos/spiceai/spiceai/merges\",\"archive_url\":\"https://api.github.com/repos/spiceai/spiceai/{archive_format}{/ref}\",\"downloads_url\":\"https://api.github.com/repos/spiceai/spiceai/downloads\",\"issues_url\":\"https://api.github.com/repos/spiceai/spiceai/issues{/number}\",\"pulls_url\":\"https://api.github.com/repos/spiceai/spiceai/pulls{/number}\",\"milestones_url\":\"https://api.github.com/repos/spiceai/spiceai/milestones{/number}\",\"notifications_url\":\"https://api.github.com/repos/spiceai/spiceai/notifications{?since,all,participating}\",\"labels_url\":\"https://api.github.com/repos/spiceai/spiceai/labels{/name}\",\"releases_url\":\"https://api.github.com/repos/spiceai/spiceai/releases{/id}\",\"deployments_url\":\"https://api.github.com/repos/spiceai/spiceai/deployments\",\"created_at\":\"2021-08-08T23:26:13Z\",\"updated_at\":\"2024-07-02T00:43:42Z\",\"pushed_at\":\"2024-07-02T02:37:08Z\",\"git_url\":\"git://github.com/spiceai/spiceai.git\",\"ssh_url\":\"git@github.com:spiceai/spiceai.git\",\"clone_url\":\"https://github.com/spiceai/spiceai.git\",\"svn_url\":\"https://github.com/spiceai/spiceai\",\"homepage\":\"https://docs.spiceai.org\",\"size\":6762,\"stargazers_count\":1610,\"watchers_count\":1610,\"language\":\"Rust\",\"has_issues\":true,\"has_projects\":true,\"has_downloads\":true,\"has_wiki\":false,\"has_pages\":false,\"has_discussions\":false,\"forks_count\":66,\"mirror_url\":null,\"archived\":false,\"disabled\":false,\"open_issues_count\":68,\"license\":{\"key\":\"apache-2.0\",\"name\":\"Apache License 2.0\",\"spdx_id\":\"Apache-2.0\",\"url\":\"https://api.github.com/licenses/apache-2.0\",\"node_id\":\"MDc6TGljZW5zZTI=\"},\"allow_forking\":true,\"is_template\":false,\"web_commit_signoff_required\":false,\"topics\":[\"artificial-intelligence\",\"data\",\"developers\",\"infrastructure\",\"machine-learning\",\"sql\",\"time-series\"],\"visibility\":\"public\",\"forks\":66,\"open_issues\":68,\"watchers\":1610,\"default_branch\":\"trunk\"}},\"_links\":{\"self\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/pulls/1843\"},\"html\":{\"href\":\"https://github.com/spiceai/spiceai/pull/1843\"},\"issue\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/issues/1843\"},\"comments\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/issues/1843/comments\"},\"review_comments\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/pulls/1843/comments\"},\"review_comment\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/pulls/comments{/number}\"},\"commits\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/pulls/1843/commits\"},\"statuses\":{\"href\":\"https://api.github.com/repos/spiceai/spiceai/statuses/f2cb013bbaa07d7ddae826e3192bae416336a528\"}},\"author_association\":\"CONTRIBUTOR\",\"auto_merge\":null,\"active_lock_reason\":null,\"merged\":false,\"mergeable\":null,\"rebaseable\":null,\"mergeable_state\":\"unknown\",\"merged_by\":null,\"comments\":0,\"review_comments\":0,\"maintainer_can_modify\":false,\"commits\":1,\"additions\":0,\"deletions\":6,\"changed_files\":1}},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\",\"org\":{\"id\":73862742,\"login\":\"spiceai\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/spiceai\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/73862742?\"}},{\"id\":\"39785531608\",\"type\":\"PushEvent\",\"actor\":{\"id\":100567891,\"login\":\"greesh13\",\"display_login\":\"greesh13\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/greesh13\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/100567891?\"},\"repo\":{\"id\":822340669,\"name\":\"greesh13/py4j_python_package\",\"url\":\"https://api.github.com/repos/greesh13/py4j_python_package\"},\"payload\":{\"repository_id\":822340669,\"push_id\":19131669345,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"5e48f76c064f5ca558dcfd1bc1170281811a25d4\",\"before\":\"5a5143fb93b4a2946fec388f98ec0c0c5419eb33\",\"commits\":[{\"sha\":\"5e48f76c064f5ca558dcfd1bc1170281811a25d4\",\"author\":{\"email\":\"greeshmashekhar.y@gmail.com\",\"name\":\"greesh13\"},\"message\":\"Created a package with ja file and .sh files\",\"distinct\":true,\"url\":\"https://api.github.com/repos/greesh13/py4j_python_package/commits/5e48f76c064f5ca558dcfd1bc1170281811a25d4\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531615\",\"type\":\"CreateEvent\",\"actor\":{\"id\":173746182,\"login\":\"JavierCaroLazo\",\"display_login\":\"JavierCaroLazo\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/JavierCaroLazo\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/173746182?\"},\"repo\":{\"id\":822880010,\"name\":\"JavierCaroLazo/final\",\"url\":\"https://api.github.com/repos/JavierCaroLazo/final\"},\"payload\":{\"ref\":null,\"ref_type\":\"repository\",\"master_branch\":\"main\",\"description\":null,\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531601\",\"type\":\"PushEvent\",\"actor\":{\"id\":92560540,\"login\":\"amazon-codecatalyst[bot]\",\"display_login\":\"amazon-codecatalyst\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/amazon-codecatalyst[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/92560540?\"},\"repo\":{\"id\":811011206,\"name\":\"SrcsProdPDXCanaryUser/github-Update\",\"url\":\"https://api.github.com/repos/SrcsProdPDXCanaryUser/github-Update\"},\"payload\":{\"repository_id\":811011206,\"push_id\":19131669339,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"2446d562f4906e76feda9d258d235a115802ac2e\",\"before\":\"9199d74d60210ff9c5b8a8a502e2b4f1165c998c\",\"commits\":[{\"sha\":\"2446d562f4906e76feda9d258d235a115802ac2e\",\"author\":{\"email\":\"92560540+amazon-codecatalyst[bot]@users.noreply.github.com\",\"name\":\"amazon-codecatalyst[bot]\"},\"message\":\"Add commit message\",\"distinct\":true,\"url\":\"https://api.github.com/repos/SrcsProdPDXCanaryUser/github-Update/commits/2446d562f4906e76feda9d258d235a115802ac2e\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531571\",\"type\":\"PushEvent\",\"actor\":{\"id\":33493135,\"login\":\"jossimunoz\",\"display_login\":\"jossimunoz\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/jossimunoz\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/33493135?\"},\"repo\":{\"id\":820112294,\"name\":\"jossimunoz/obsidian-note-shield\",\"url\":\"https://api.github.com/repos/jossimunoz/obsidian-note-shield\"},\"payload\":{\"repository_id\":820112294,\"push_id\":19131669317,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/master\",\"head\":\"96b36e76ccd445240adc938a5655be9b5e1678cb\",\"before\":\"cbddfe7c79d9ad99bbea3a5be63dac67f18f8efb\",\"commits\":[{\"sha\":\"96b36e76ccd445240adc938a5655be9b5e1678cb\",\"author\":{\"email\":\"jossimunoz@gmail.com\",\"name\":\"Jossi\"},\"message\":\"fix release workflow\",\"distinct\":true,\"url\":\"https://api.github.com/repos/jossimunoz/obsidian-note-shield/commits/96b36e76ccd445240adc938a5655be9b5e1678cb\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531547\",\"type\":\"PushEvent\",\"actor\":{\"id\":173302144,\"login\":\"rafazomb\",\"display_login\":\"rafazomb\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/rafazomb\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/173302144?\"},\"repo\":{\"id\":822846504,\"name\":\"rafazomb/academic-projects\",\"url\":\"https://api.github.com/repos/rafazomb/academic-projects\"},\"payload\":{\"repository_id\":822846504,\"push_id\":19131669313,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"86f88a00266ee1130213caf224331a5e8e3f680a\",\"before\":\"5717b7ab9f7c5b4254a3878e644026846ba60acb\",\"commits\":[{\"sha\":\"86f88a00266ee1130213caf224331a5e8e3f680a\",\"author\":{\"email\":\"rafazombyt@gmail.com\",\"name\":\"rafazomb\"},\"message\":\"Rename exercicio_pratico_2_segundo_semestre.ipynb to python-codes/exercicio_pratico_2_segundo_semestre.ipynb\",\"distinct\":true,\"url\":\"https://api.github.com/repos/rafazomb/academic-projects/commits/86f88a00266ee1130213caf224331a5e8e3f680a\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531568\",\"type\":\"PushEvent\",\"actor\":{\"id\":97435656,\"login\":\"HttpAnimation\",\"display_login\":\"HttpAnimation\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/HttpAnimation\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/97435656?\"},\"repo\":{\"id\":818755106,\"name\":\"HttpAnimation/1.12.2\",\"url\":\"https://api.github.com/repos/HttpAnimation/1.12.2\"},\"payload\":{\"repository_id\":818755106,\"push_id\":19131669318,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"71971a82f0ab7f972c37524a0e817b211cd0750b\",\"before\":\"4df633ae0d7085b05baee4f591154458d7b37667\",\"commits\":[{\"sha\":\"71971a82f0ab7f972c37524a0e817b211cd0750b\",\"author\":{\"email\":\"shawndouglasyt@gmail.com\",\"name\":\"HttpAnimation\"},\"message\":\"Automated commit\",\"distinct\":true,\"url\":\"https://api.github.com/repos/HttpAnimation/1.12.2/commits/71971a82f0ab7f972c37524a0e817b211cd0750b\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531565\",\"type\":\"CreateEvent\",\"actor\":{\"id\":166895733,\"login\":\"swa-runner-app[bot]\",\"display_login\":\"swa-runner-app\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/swa-runner-app[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/166895733?\"},\"repo\":{\"id\":822875684,\"name\":\"static-web-apps-testing-org/swa874df7d8c19b432bba23f5fb3a7153a2\",\"url\":\"https://api.github.com/repos/static-web-apps-testing-org/swa874df7d8c19b432bba23f5fb3a7153a2\"},\"payload\":{\"ref\":\"prBranch\",\"ref_type\":\"branch\",\"master_branch\":\"main\",\"description\":\"swa874df7d8c19b432bba23f5fb3a7153a2\",\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\",\"org\":{\"id\":96167003,\"login\":\"static-web-apps-testing-org\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/static-web-apps-testing-org\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/96167003?\"}},{\"id\":\"39785531529\",\"type\":\"PushEvent\",\"actor\":{\"id\":53584728,\"login\":\"TheRealAmazonKendra\",\"display_login\":\"TheRealAmazonKendra\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/TheRealAmazonKendra\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/53584728?\"},\"repo\":{\"id\":312982101,\"name\":\"TheRealAmazonKendra/aws-cdk\",\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk\"},\"payload\":{\"repository_id\":312982101,\"push_id\":19131669259,\"size\":11,\"distinct_size\":4,\"ref\":\"refs/heads/main\",\"head\":\"84fc01f479e598e2704721be23c6f038fe25d62b\",\"before\":\"9a5d4f023e6ac058075e7eebf9073ae02f79ebbe\",\"commits\":[{\"sha\":\"5d155d796bb024b026045636692e64cfc738eac7\",\"author\":{\"email\":\"53584728+TheRealAmazonKendra@users.noreply.github.com\",\"name\":\"Kendra Neil\"},\"message\":\"revert: fix(core): overrideLogicalId validation (#30695)\\n\\nReverts aws/aws-cdk#29708 due to https://github.com/aws/aws-cdk/issues/30669\\n\\nCloses https://github.com/aws/aws-cdk/issues/30669\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/5d155d796bb024b026045636692e64cfc738eac7\"},{\"sha\":\"86b6a95ddb6b5be34f059cba5fa42573152e231e\",\"author\":{\"email\":\"69879391+scanlonp@users.noreply.github.com\",\"name\":\"Parker Scanlon\"},\"message\":\"chore(release): 2.147.2\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/86b6a95ddb6b5be34f059cba5fa42573152e231e\"},{\"sha\":\"680cc43933f1e09b17ec42544645ad587f617e17\",\"author\":{\"email\":\"69879391+scanlonp@users.noreply.github.com\",\"name\":\"Parker Scanlon\"},\"message\":\"chore: clean up changelogs\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/680cc43933f1e09b17ec42544645ad587f617e17\"},{\"sha\":\"f4b08972e2514ea249157eeea7227469fd601eeb\",\"author\":{\"email\":\"37929162+mergify[bot]@users.noreply.github.com\",\"name\":\"mergify[bot]\"},\"message\":\"chore(release): v2.147.2 (#30698)\\n\\nSee CHANGELOG\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/f4b08972e2514ea249157eeea7227469fd601eeb\"},{\"sha\":\"4ceecedd3d91465b29db21b10239937b99b5f79c\",\"author\":{\"email\":\"43080478+aws-cdk-automation@users.noreply.github.com\",\"name\":\"AWS CDK Automation\"},\"message\":\"feat: update L1 CloudFormation resource definitions (#30722)\\n\\nUpdates the L1 CloudFormation resource definitions with the latest changes from `@aws-cdk/aws-service-spec`\\n\\n**L1 CloudFormation resource definition changes:**\\n```\\n├[~] service aws-applicationsignals\\n│ └ resources\\n│    └[~] resource AWS::ApplicationSignals::ServiceLevelObjective\\n│      ├  - documentation: Resource Type definition for AWS::ApplicationSignals::ServiceLevelObjective\\n│      │  + documentation: Creates or updates a service level objective (SLO), which can help you ensure that your critical business operations are meeting customer expectations. Use SLOs to set and track specific target levels for the reliability and availability of your applications and services. SLOs use service level indicators (SLIs) to calculate whether the application is performing at the level that you want.\\n│      │  Create an SLO to set a target for a service or operation’s availability or latency. CloudWatch measures this target frequently you can find whether it has been breached.\\n│      │  When you create an SLO, you set an *attainment goal* for it. An *attainment goal* is the ratio of good periods that meet the threshold requirements to the total periods within the interval. For example, an attainment goal of 99.9% means that within your interval, you are targeting 99.9% of the periods to be in healthy state.\\n│      │  After you have created an SLO, you can retrieve error budget reports for it. An *error budget* is the number of periods or amount of time that your service can accumulate during an interval before your overall SLO budget health is breached and the SLO is considered to be unmet. for example, an SLO with a threshold that 99.95% of requests must be completed under 2000ms every month translates to an error budget of 21.9 minutes of downtime per month.\\n│      │  When you call this operation, Application Signals creates the *AWSServiceRoleForCloudWatchApplicationSignals* service-linked role, if it doesn't already exist in your account. This service- linked role has the following permissions:\\n│      │  - `xray:GetServiceGraph`\\n│      │  - `logs:StartQuery`\\n│      │  - `logs:GetQueryResults`\\n│      │  - `cloudwatch:GetMetricData`\\n│      │  - `cloudwatch:ListMetrics`\\n│      │  - `tag:GetResources`\\n│      │  - `autoscaling:DescribeAutoScalingGroups`\\n│      │  You can easily set SLO targets for your applications that are discovered by Application Signals, using critical metrics such as latency and availability. You can also set SLOs against any CloudWatch metric or math expression that produces a time series.\\n│      │  For more information about SLOs, see [Service level objectives (SLOs)](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-ServiceLevelObjectives.html) .\\n│      ├ properties\\n│      │  ├ Description: (documentation changed)\\n│      │  ├ Goal: (documentation changed)\\n│      │  ├ Name: (documentation changed)\\n│      │  ├ Sli: (documentation changed)\\n│      │  └ Tags: (documentation changed)\\n│      ├ attributes\\n│      │  ├ CreatedTime: (documentation changed)\\n│      │  └ LastUpdatedTime: (documentation changed)\\n│      └ types\\n│         ├[~] type CalendarInterval\\n│         │ └ properties\\n│         │    ├ Duration: (documentation changed)\\n│         │    └ StartTime: (documentation changed)\\n│         ├[~] type Dimension\\n│         │ ├  - documentation: A dimension is a name/value pair that is part of the identity of a metric. Because dimensions are part of the unique identifier for a metric, whenever you add a unique name/value pair to one of your metrics, you are creating a new variation of that metric. For example, many Amazon EC2 metrics publish `InstanceId` as a dimension name, and the actual instance ID as the value for that dimension. You can assign up to 30 dimensions to a metric.\\n│         │ │  + documentation: A dimension is a name/value pair that is part of the identity of a metric. Because dimensions are part of the unique identifier for a metric, whenever you add a unique name/value pair to one of your metrics, you are creating a new variation of that metric. For example, many Amazon EC2 metrics publish `InstanceId` as a dimension name, and the actual instance ID as the value for that dimension.\\n│         │ │  You can assign up to 30 dimensions to a metric.\\n│         │ └ properties\\n│         │    ├ Name: (documentation changed)\\n│         │    └ Value: (documentation changed)\\n│         ├[~] type Goal\\n│         │ ├  - documentation: A structure that contains the attributes that determine the goal of the SLO. This includes the time period for evaluation and the attainment threshold.\\n│         │ │  + documentation: This structure contains the attributes that determine the goal of an SLO. This includes the time period for evaluation and the attainment threshold.\\n│         │ └ properties\\n│         │    ├ AttainmentGoal: (documentation changed)\\n│         │    └ Interval: (documentation changed)\\n│         ├[~] type Interval\\n│         │ ├  - documentation: The time period used to evaluate the SLO. It can be either a calendar interval or rolling interval.\\n│         │ │  If you omit this parameter, a rolling interval of 7 days is used.\\n│         │ │  + documentation: The time period used to evaluate the SLO. It can be either a calendar interval or rolling interval.\\n│         │ └ properties\\n│         │    ├ CalendarInterval: (documentation changed)\\n│         │    └ RollingInterval: (documentation changed)\\n│         ├[~] type Metric\\n│         │ ├  - documentation: This structure defines the metric used for a service level indicator, including the metric name, namespace, and dimensions.\\n│         │ │  + documentation: This structure defines the metric used for a service level indicator, including the metric name, namespace, and dimensions\\n│         │ └ properties\\n│         │    ├ Dimensions: (documentation changed)\\n│         │    └ Namespace: (documentation changed)\\n│         ├[~] type MetricDataQuery\\n│         │ ├  - documentation: Use this structure to define a metric or metric math expression that you want to use as for a service level objective.\\n│         │ │  Each `MetricDataQuery` in the `MetricDataQueries` array specifies either a metric to retrieve, or a metric math expression to be performed on retrieved metrics. A single `MetricDataQueries` array can include as many as 20 `MetricDataQuery` structures in the array. The 20 structures can include as many as 10 structures that contain a `MetricStat` parameter to retrieve a metric, and as many as 10 structures that contain the `Expression` parameter to perform a math expression. Of those Expression structures, exactly one must have true as the value for `ReturnData`. The result of this expression used for the SLO.\\n│         │ │  + documentation: Use this structure to define a metric or metric math expression that you want to use as for a service level objective.\\n│         │ │  Each `MetricDataQuery` in the `MetricDataQueries` array specifies either a metric to retrieve, or a metric math expression to be performed on retrieved metrics. A single `MetricDataQueries` array can include as many as 20 `MetricDataQuery` structures in the array. The 20 structures can include as many as 10 structures that contain a `MetricStat` parameter to retrieve a metric, and as many as 10 structures that contain the `Expression` parameter to perform a math expression. Of those `Expression` structures, exactly one must have true as the value for `ReturnData` . The result of this expression used for the SLO.\\n│         │ │  For more information about metric math expressions, see [Use metric math](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/using-metric-math.html) .\\n│         │ │  Within each `MetricDataQuery` object, you must specify either `Expression` or `MetricStat` but not both.\\n│         │ └ properties\\n│         │    ├ AccountId: (documentation changed)\\n│         │    ├ Expression: (documentation changed)\\n│         │    ├ Id: (documentation changed)\\n│         │    ├ MetricStat: (documentation changed)\\n│         │    └ ReturnData: (documentation changed)\\n│         ├[~] type MetricStat\\n│         │ ├  - documentation: A metric to be used directly for the SLO, or to be used in the math expression that will be used for the SLO. Within one MetricDataQuery object, you must specify either Expression or MetricStat but not both.\\n│         │ │  + documentation: This structure defines the metric to be used as the service level indicator, along with the statistics, period, and unit.\\n│         │ └ properties\\n│         │    ├ Metric: (documentation changed)\\n│         │    ├ Period: (documentation changed)\\n│         │    ├ Stat: (documentation changed)\\n│         │    └ Unit: (documentation changed)\\n│         ├[~] type RollingInterval\\n│         │ ├  - documentation: If the interval is a calendar interval, this structure contains the interval specifications.\\n│         │ │  + documentation: If the interval for this SLO is a rolling interval, this structure contains the interval specifications.\\n│         │ └ properties\\n│         │    ├ Duration: (documentation changed)\\n│         │    └ DurationUnit: (documentation changed)\\n│         ├[~] type Sli\\n│         │ ├  - documentation: This structure contains information about the performance metric that an SLO monitors.\\n│         │ │  + documentation: This structure specifies the information about the service and the performance metric that an SLO is to monitor.\\n│         │ └ properties\\n│         │    ├ ComparisonOperator: (documentation changed)\\n│         │    └ SliMetric: (documentation changed)\\n│         └[~] type SliMetric\\n│           ├  - documentation: A structure that contains information about the metric that the SLO monitors.\\n│           │  + documentation: Use this structure to specify the metric to be used for the SLO.\\n│           └ properties\\n│              ├ KeyAttributes: (documentation changed)\\n│              ├ MetricDataQueries: (documentation changed)\\n│              ├ MetricType: (documentation changed)\\n│              ├ OperationName: (documentation changed)\\n│              └ Statistic: (documentation changed)\\n├[~] service aws-apptest\\n│ └ resources\\n│    └[~] resource AWS::AppTest::TestCase\\n│      ├  - documentation: Represents a Test Case that can be captured and executed\\n│      │  + documentation: Creates a test case for an application.\\n│      │  For more information about test cases, see [Test cases](https://docs.aws.amazon.com/m2/latest/userguide/testing-test-cases.html) and [Application Testing concepts](https://docs.aws.amazon.com/m2/latest/userguide/concepts-apptest.html) in the *AWS Mainframe Modernization User Guide* .\\n│      ├ properties\\n│      │  ├ Description: (documentation changed)\\n│      │  ├ Name: (documentation changed)\\n│      │  ├ Steps: (documentation changed)\\n│      │  └ Tags: (documentation changed)\\n│      ├ attributes\\n│      │  ├ CreationTime: (documentation changed)\\n│      │  ├ LastUpdateTime: (documentation changed)\\n│      │  ├ Status: (documentation changed)\\n│      │  ├ TestCaseArn: (documentation changed)\\n│      │  ├ TestCaseId: (documentation changed)\\n│      │  └ TestCaseVersion: (documentation changed)\\n│      └ types\\n│         ├[~] type Batch\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Defines a batch.\\n│         │ └ properties\\n│         │    ├ BatchJobName: (documentation changed)\\n│         │    ├ BatchJobParameters: (documentation changed)\\n│         │    └ ExportDataSetNames: (documentation changed)\\n│         ├[~] type CloudFormationAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the CloudFormation action.\\n│         │ └ properties\\n│         │    ├ ActionType: (documentation changed)\\n│         │    └ Resource: (documentation changed)\\n│         ├[~] type CompareAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Compares the action.\\n│         │ └ properties\\n│         │    ├ Input: (documentation changed)\\n│         │    └ Output: (documentation changed)\\n│         ├[~] type DatabaseCDC\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Defines the Change Data Capture (CDC) of the database.\\n│         │ └ properties\\n│         │    ├ SourceMetadata: (documentation changed)\\n│         │    └ TargetMetadata: (documentation changed)\\n│         ├[~] type DataSet\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Defines a data set.\\n│         │ └ properties\\n│         │    ├ Ccsid: (documentation changed)\\n│         │    ├ Format: (documentation changed)\\n│         │    ├ Length: (documentation changed)\\n│         │    ├ Name: (documentation changed)\\n│         │    └ Type: (documentation changed)\\n│         ├[~] type FileMetadata\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies a file metadata.\\n│         │ └ properties\\n│         │    ├ DatabaseCDC: (documentation changed)\\n│         │    └ DataSets: (documentation changed)\\n│         ├[~] type Input\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the input.\\n│         │ └ properties\\n│         │    └ File: (documentation changed)\\n│         ├[~] type InputFile\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the input file.\\n│         │ └ properties\\n│         │    ├ FileMetadata: (documentation changed)\\n│         │    ├ SourceLocation: (documentation changed)\\n│         │    └ TargetLocation: (documentation changed)\\n│         ├[~] type M2ManagedActionProperties\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the AWS Mainframe Modernization managed action properties.\\n│         │ └ properties\\n│         │    ├ ForceStop: (documentation changed)\\n│         │    └ ImportDataSetLocation: (documentation changed)\\n│         ├[~] type M2ManagedApplicationAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the AWS Mainframe Modernization managed application action.\\n│         │ └ properties\\n│         │    ├ ActionType: (documentation changed)\\n│         │    ├ Properties: (documentation changed)\\n│         │    └ Resource: (documentation changed)\\n│         ├[~] type M2NonManagedApplicationAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the AWS Mainframe Modernization non-managed application action.\\n│         │ └ properties\\n│         │    ├ ActionType: (documentation changed)\\n│         │    └ Resource: (documentation changed)\\n│         ├[~] type MainframeAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the mainframe action.\\n│         │ └ properties\\n│         │    ├ ActionType: (documentation changed)\\n│         │    ├ Properties: (documentation changed)\\n│         │    └ Resource: (documentation changed)\\n│         ├[~] type MainframeActionProperties\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the mainframe action properties.\\n│         │ └ properties\\n│         │    └ DmsTaskArn: (documentation changed)\\n│         ├[~] type MainframeActionType\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the mainframe action type.\\n│         │ └ properties\\n│         │    ├ Batch: (documentation changed)\\n│         │    └ Tn3270: (documentation changed)\\n│         ├[~] type Output\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies an output.\\n│         │ └ properties\\n│         │    └ File: (documentation changed)\\n│         ├[~] type OutputFile\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies an output file.\\n│         │ └ properties\\n│         │    └ FileLocation: (documentation changed)\\n│         ├[~] type ResourceAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies a resource action.\\n│         │ └ properties\\n│         │    ├ CloudFormationAction: (documentation changed)\\n│         │    ├ M2ManagedApplicationAction: (documentation changed)\\n│         │    └ M2NonManagedApplicationAction: (documentation changed)\\n│         ├[~] type Script\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the script.\\n│         │ └ properties\\n│         │    ├ ScriptLocation: (documentation changed)\\n│         │    └ Type: (documentation changed)\\n│         ├[~] type SourceDatabaseMetadata\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the source database metadata.\\n│         │ └ properties\\n│         │    ├ CaptureTool: (documentation changed)\\n│         │    └ Type: (documentation changed)\\n│         ├[~] type Step\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Defines a step.\\n│         │ └ properties\\n│         │    ├ Action: (documentation changed)\\n│         │    ├ Description: (documentation changed)\\n│         │    └ Name: (documentation changed)\\n│         ├[~] type StepAction\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies a step action.\\n│         │ └ properties\\n│         │    ├ CompareAction: (documentation changed)\\n│         │    ├ MainframeAction: (documentation changed)\\n│         │    └ ResourceAction: (documentation changed)\\n│         ├[~] type TargetDatabaseMetadata\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies a target database metadata.\\n│         │ └ properties\\n│         │    ├ CaptureTool: (documentation changed)\\n│         │    └ Type: (documentation changed)\\n│         ├[~] type TestCaseLatestVersion\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: Specifies the latest version of a test case.\\n│         │ └ properties\\n│         │    ├ Status: (documentation changed)\\n│         │    └ Version: (documentation changed)\\n│         └[~] type TN3270\\n│           ├  - documentation: undefined\\n│           │  + documentation: Specifies the TN3270 protocol.\\n│           └ properties\\n│              ├ ExportDataSetNames: (documentation changed)\\n│              └ Script: (documentation changed)\\n├[~] service aws-backup\\n│ └ resources\\n│    ├[~] resource AWS::Backup::BackupVault\\n│    │ └ properties\\n│    │    └ BackupVaultName: (documentation changed)\\n│    └[~] resource AWS::Backup::RestoreTestingSelection\\n│      └ types\\n│         └[~] type ProtectedResourceConditions\\n│           └  - documentation: The conditions that you define for resources in your restore testing plan using tags.\\n│              For example, `\\\"StringEquals\\\": { \\\"Key\\\": \\\"aws:ResourceTag/CreatedByCryo\\\", \\\"Value\\\": \\\"true\\\" },` . Condition operators are case sensitive.\\n│              + documentation: The conditions that you define for resources in your restore testing plan using tags.\\n├[~] service aws-bedrock\\n│ └ resources\\n│    └[~] resource AWS::Bedrock::Agent\\n│      ├ properties\\n│      │  └[+] GuardrailConfiguration: GuardrailConfiguration\\n│      └ types\\n│         └[+] type GuardrailConfiguration\\n│           ├  documentation: Configuration information for a guardrail that you use with the `Converse` action.\\n│           │  name: GuardrailConfiguration\\n│           └ properties\\n│              ├GuardrailIdentifier: string\\n│              └GuardrailVersion: string\\n├[~] service aws-cloudtrail\\n│ └ resources\\n│    └[~] resource AWS::CloudTrail::Trail\\n│      ├ properties\\n│      │  ├ CloudWatchLogsLogGroupArn: (documentation changed)\\n│      │  └ CloudWatchLogsRoleArn: (documentation changed)\\n│      └ types\\n│         └[~] type DataResource\\n│           ├  - documentation: Data events provide information about the resource operations performed on or within a resource itself. These are also known as data plane operations. You can specify up to 250 data resources for a trail.\\n│           │  Configure the `DataResource` to specify the resource type and resource ARNs for which you want to log data events.\\n│           │  You can specify the following resource types in your event selectors for your trail:\\n│           │  - `AWS::DynamoDB::Table`\\n│           │  - `AWS::Lambda::Function`\\n│           │  - `AWS::S3::Object`\\n│           │  > The total number of allowed data resources is 250. This number can be distributed between 1 and 5 event selectors, but the total cannot exceed 250 across all selectors for the trail.\\n│           │  > \\n│           │  > If you are using advanced event selectors, the maximum total number of values for all conditions, across all advanced event selectors for the trail, is 500. \\n│           │  The following example demonstrates how logging works when you configure logging of all data events for an S3 bucket named `bucket-1` . In this example, the CloudTrail user specified an empty prefix, and the option to log both `Read` and `Write` data events.\\n│           │  - A user uploads an image file to `bucket-1` .\\n│           │  - The `PutObject` API operation is an Amazon S3 object-level API. It is recorded as a data event in CloudTrail. Because the CloudTrail user specified an S3 bucket with an empty prefix, events that occur on any object in that bucket are logged. The trail processes and logs the event.\\n│           │  - A user uploads an object to an Amazon S3 bucket named `arn:aws:s3:::bucket-2` .\\n│           │  - The `PutObject` API operation occurred for an object in an S3 bucket that the CloudTrail user didn't specify for the trail. The trail doesn’t log the event.\\n│           │  The following example demonstrates how logging works when you configure logging of AWS Lambda data events for a Lambda function named *MyLambdaFunction* , but not for all Lambda functions.\\n│           │  - A user runs a script that includes a call to the *MyLambdaFunction* function and the *MyOtherLambdaFunction* function.\\n│           │  - The `Invoke` API operation on *MyLambdaFunction* is an Lambda API. It is recorded as a data event in CloudTrail. Because the CloudTrail user specified logging data events for *MyLambdaFunction* , any invocations of that function are logged. The trail processes and logs the event.\\n│           │  - The `Invoke` API operation on *MyOtherLambdaFunction* is an Lambda API. Because the CloudTrail user did not specify logging data events for all Lambda functions, the `Invoke` operation for *MyOtherLambdaFunction* does not match the function specified for the trail. The trail doesn’t log the event.\\n│           │  + documentation: Data events provide information about the resource operations performed on or within a resource itself. These are also known as data plane operations. You can specify up to 250 data resources for a trail.\\n│           │  Configure the `DataResource` to specify the resource type and resource ARNs for which you want to log data events.\\n│           │  You can specify the following resource types in your event selectors for your trail:\\n│           │  - `AWS::DynamoDB::Table`\\n│           │  - `AWS::Lambda::Function`\\n│           │  - `AWS::S3::Object`\\n│           │  > The total number of allowed data resources is 250. This number can be distributed between 1 and 5 event selectors, but the total cannot exceed 250 across all selectors for the trail.\\n│           │  > \\n│           │  > If you are using advanced event selectors, the maximum total number of values for all conditions, across all advanced event selectors for the trail, is 500. \\n│           │  The following example demonstrates how logging works when you configure logging of all data events for an S3 bucket named `DOC-EXAMPLE-BUCKET1` . In this example, the CloudTrail user specified an empty prefix, and the option to log both `Read` and `Write` data events.\\n│           │  - A user uploads an image file to `DOC-EXAMPLE-BUCKET1` .\\n│           │  - The `PutObject` API operation is an Amazon S3 object-level API. It is recorded as a data event in CloudTrail. Because the CloudTrail user specified an S3 bucket with an empty prefix, events that occur on any object in that bucket are logged. The trail processes and logs the event.\\n│           │  - A user uploads an object to an Amazon S3 bucket named `arn:aws:s3:::DOC-EXAMPLE-BUCKET1` .\\n│           │  - The `PutObject` API operation occurred for an object in an S3 bucket that the CloudTrail user didn't specify for the trail. The trail doesn’t log the event.\\n│           │  The following example demonstrates how logging works when you configure logging of AWS Lambda data events for a Lambda function named *MyLambdaFunction* , but not for all Lambda functions.\\n│           │  - A user runs a script that includes a call to the *MyLambdaFunction* function and the *MyOtherLambdaFunction* function.\\n│           │  - The `Invoke` API operation on *MyLambdaFunction* is an Lambda API. It is recorded as a data event in CloudTrail. Because the CloudTrail user specified logging data events for *MyLambdaFunction* , any invocations of that function are logged. The trail processes and logs the event.\\n│           │  - The `Invoke` API operation on *MyOtherLambdaFunction* is an Lambda API. Because the CloudTrail user did not specify logging data events for all Lambda functions, the `Invoke` operation for *MyOtherLambdaFunction* does not match the function specified for the trail. The trail doesn’t log the event.\\n│           └ properties\\n│              └ Values: (documentation changed)\\n├[~] service aws-codeartifact\\n│ └ resources\\n│    ├[~] resource AWS::CodeArtifact::Domain\\n│    │ └ properties\\n│    │    └ EncryptionKey: (documentation changed)\\n│    └[~] resource AWS::CodeArtifact::Repository\\n│      └ properties\\n│         └ DomainOwner: (documentation changed)\\n├[~] service aws-codebuild\\n│ └ resources\\n│    └[~] resource AWS::CodeBuild::Project\\n│      └ types\\n│         ├[~] type ProjectTriggers\\n│         │ └ properties\\n│         │    └[+] ScopeConfiguration: ScopeConfiguration\\n│         ├[+] type ScopeConfiguration\\n│         │ ├  name: ScopeConfiguration\\n│         │ └ properties\\n│         │    └Name: string (required)\\n│         └[~] type WebhookFilter\\n│           └ properties\\n│              └ Type: (documentation changed)\\n├[~] service aws-cognito\\n│ └ resources\\n│    ├[~] resource AWS::Cognito::UserPoolClient\\n│    │ └ properties\\n│    │    └ DefaultRedirectURI: (documentation changed)\\n│    └[~] resource AWS::Cognito::UserPoolResourceServer\\n│      └ attributes\\n│         └[-] Id: string\\n├[~] service aws-datasync\\n│ └ resources\\n│    └[~] resource AWS::DataSync::Agent\\n│      └ properties\\n│         ├ ActivationKey: (documentation changed)\\n│         ├ AgentName: (documentation changed)\\n│         └ SubnetArns: (documentation changed)\\n├[~] service aws-deadline\\n│ └ resources\\n│    └[~] resource AWS::Deadline::Monitor\\n│      └ attributes\\n│         └ Arn: (documentation changed)\\n├[~] service aws-dms\\n│ └ resources\\n│    └[~] resource AWS::DMS::ReplicationConfig\\n│      └ attributes\\n│         └ ReplicationConfigArn: (documentation changed)\\n├[~] service aws-ec2\\n│ └ resources\\n│    ├[~] resource AWS::EC2::EC2Fleet\\n│    │ ├  - documentation: Specifies the configuration information to launch a fleet--or group--of instances. An EC2 Fleet can launch multiple instance types across multiple Availability Zones, using the On-Demand Instance, Reserved Instance, and Spot Instance purchasing models together. Using EC2 Fleet, you can define separate On-Demand and Spot capacity targets, specify the instance types that work best for your applications, and specify how Amazon EC2 should distribute your fleet capacity within each purchasing model. For more information, see [Launching an EC2 Fleet](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-fleet.html) in the *Amazon EC2 User Guide for Linux Instances* .\\n│    │ │  + documentation: Specifies the configuration information to launch a fleet--or group--of instances. An EC2 Fleet can launch multiple instance types across multiple Availability Zones, using the On-Demand Instance, Reserved Instance, and Spot Instance purchasing models together. Using EC2 Fleet, you can define separate On-Demand and Spot capacity targets, specify the instance types that work best for your applications, and specify how Amazon EC2 should distribute your fleet capacity within each purchasing model. For more information, see [Launching an EC2 Fleet](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-fleet.html) in the *Amazon EC2 User Guide* .\\n│    │ └ types\\n│    │    └[~] type InstanceRequirementsRequest\\n│    │      └ properties\\n│    │         └ MaxSpotPriceAsPercentageOfOptimalOnDemandPrice: (documentation changed)\\n│    ├[~] resource AWS::EC2::Host\\n│    │ └  - documentation: Allocates a fully dedicated physical server for launching EC2 instances. Because the host is fully dedicated for your use, it can help you address compliance requirements and reduce costs by allowing you to use your existing server-bound software licenses. For more information, see [Dedicated Hosts](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html) in the *Amazon EC2 User Guide for Linux Instances* .\\n│    │    + documentation: Allocates a fully dedicated physical server for launching EC2 instances. Because the host is fully dedicated for your use, it can help you address compliance requirements and reduce costs by allowing you to use your existing server-bound software licenses. For more information, see [Dedicated Hosts](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html) in the *Amazon EC2 User Guide* .\\n│    ├[~] resource AWS::EC2::Instance\\n│    │ └ types\\n│    │    └[~] type ElasticGpuSpecification\\n│    │      └  - documentation: > Amazon Elastic Graphics reached end of life on January 8, 2024. For workloads that require graphics acceleration, we recommend that you use Amazon EC2 G4ad, G4dn, or G5 instances. \\n│    │         Specifies the type of Elastic GPU. An Elastic GPU is a GPU resource that you can attach to your Amazon EC2 instance to accelerate the graphics performance of your applications. For more information, see [Amazon EC2 Elastic GPUs](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/elastic-graphics.html) in the *Amazon EC2 User Guide for Windows Instances* .\\n│    │         `ElasticGpuSpecification` is a property of the [AWS::EC2::Instance](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html) resource.\\n│    │         + documentation: > Amazon Elastic Graphics reached end of life on January 8, 2024. For workloads that require graphics acceleration, we recommend that you use Amazon EC2 G4ad, G4dn, or G5 instances. \\n│    │         Specifies the type of Elastic GPU. An Elastic GPU is a GPU resource that you can attach to your Amazon EC2 instance to accelerate the graphics performance of your applications.\\n│    │         `ElasticGpuSpecification` is a property of the [AWS::EC2::Instance](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html) resource.\\n│    ├[~] resource AWS::EC2::InstanceConnectEndpoint\\n│    │ └ properties\\n│    │    └ PreserveClientIp: (documentation changed)\\n│    ├[~] resource AWS::EC2::LaunchTemplate\\n│    │ └ types\\n│    │    ├[~] type InstanceRequirements\\n│    │    │ └ properties\\n│    │    │    └ MaxSpotPriceAsPercentageOfOptimalOnDemandPrice: (documentation changed)\\n│    │    └[~] type LaunchTemplateData\\n│    │      └ properties\\n│    │         └ UserData: (documentation changed)\\n│    ├[~] resource AWS::EC2::SecurityGroup\\n│    │ └ attributes\\n│    │    ├ GroupId: (documentation changed)\\n│    │    └ VpcId: (documentation changed)\\n│    └[~] resource AWS::EC2::SpotFleet\\n│      └ types\\n│         ├[~] type InstanceRequirementsRequest\\n│         │ └ properties\\n│         │    └ MaxSpotPriceAsPercentageOfOptimalOnDemandPrice: (documentation changed)\\n│         └[~] type SpotFleetRequestConfigData\\n│           └ properties\\n│              └ IamFleetRole: (documentation changed)\\n├[~] service aws-ecs\\n│ └ resources\\n│    ├[~] resource AWS::ECS::Service\\n│    │ └ types\\n│    │    ├[~] type LogConfiguration\\n│    │    │ ├  - documentation: The log configuration for the container. This parameter maps to `LogConfig` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the `--log-driver` option to [`docker run`](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/commandline/run/) .\\n│    │    │ │  By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition. For more information about the options for different supported log drivers, see [Configure logging drivers](https://docs.aws.amazon.com/https://docs.docker.com/engine/admin/logging/overview/) in the Docker documentation.\\n│    │    │ │  Understand the following when specifying a log configuration for your containers.\\n│    │    │ │  - Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.\\n│    │    │ │  For tasks on AWS Fargate , the supported log drivers are `awslogs` , `splunk` , and `awsfirelens` .\\n│    │    │ │  For tasks hosted on Amazon EC2 instances, the supported log drivers are `awslogs` , `fluentd` , `gelf` , `json-file` , `journald` , `logentries` , `syslog` , `splunk` , and `awsfirelens` .\\n│    │    │ │  - This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.\\n│    │    │ │  - For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the `ECS_AVAILABLE_LOGGING_DRIVERS` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide* .\\n│    │    │ │  - For tasks that are on AWS Fargate , because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.\\n│    │    │ │  + documentation: The log configuration for the container. This parameter maps to `LogConfig` in the [Create a container](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/#operation/ContainerCreate) section of the [Docker Remote API](https://docs.aws.amazon.com/https://docs.docker.com/engine/api/v1.35/) and the `--log-driver` option to [`docker run`](https://docs.aws.amazon.com/https://docs.docker.com/engine/reference/commandline/run/) .\\n│    │    │ │  By default, containers use the same logging driver that the Docker daemon uses. However, the container might use a different logging driver than the Docker daemon by specifying a log driver configuration in the container definition. For more information about the options for different supported log drivers, see [Configure logging drivers](https://docs.aws.amazon.com/https://docs.docker.com/engine/admin/logging/overview/) in the Docker documentation.\\n│    │    │ │  Understand the following when specifying a log configuration for your containers.\\n│    │    │ │  - Amazon ECS currently supports a subset of the logging drivers available to the Docker daemon. Additional log drivers may be available in future releases of the Amazon ECS container agent.\\n│    │    │ │  For tasks on AWS Fargate , the supported log drivers are `awslogs` , `splunk` , and `awsfirelens` .\\n│    │    │ │  For tasks hosted on Amazon EC2 instances, the supported log drivers are `awslogs` , `fluentd` , `gelf` , `json-file` , `journald` , `syslog` , `splunk` , and `awsfirelens` .\\n│    │    │ │  - This parameter requires version 1.18 of the Docker Remote API or greater on your container instance.\\n│    │    │ │  - For tasks that are hosted on Amazon EC2 instances, the Amazon ECS container agent must register the available logging drivers with the `ECS_AVAILABLE_LOGGING_DRIVERS` environment variable before containers placed on that instance can use these log configuration options. For more information, see [Amazon ECS container agent configuration](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-config.html) in the *Amazon Elastic Container Service Developer Guide* .\\n│    │    │ │  - For tasks that are on AWS Fargate , because you don't have access to the underlying infrastructure your tasks are hosted on, any additional software needed must be installed outside of the task. For example, the Fluentd output aggregators or a remote host running Logstash to send Gelf logs to.\\n│    │    │ └ properties\\n│    │    │    └ LogDriver: (documentation changed)\\n│    │    └[~] type ServiceConnectConfiguration\\n│    │      └ properties\\n│    │         └ LogConfiguration: (documentation changed)\\n│    └[~] resource AWS::ECS::TaskDefinition\\n│      ├ properties\\n│      │  ├ ExecutionRoleArn: (documentation changed)\\n│      │  └ TaskRoleArn: (documentation changed)\\n│      └ types\\n│         ├[~] type ContainerDefinition\\n│         │ └ properties\\n│         │    └ Cpu: (documentation changed)\\n│         ├[~] type LogConfiguration\\n│         │ └ properties\\n│         │    └ LogDriver: (documentation changed)\\n│         └[~] type Ulimit\\n│           └  - documentation: The `ulimit` settings to pass to the container.\\n│              Amazon ECS tasks hosted on AWS Fargate use the default resource limit values set by the operating system with the exception of the `nofile` resource limit parameter which AWS Fargate overrides. The `nofile` resource limit sets a restriction on the number of open files that a container can use. The default `nofile` soft limit is `1024` and the default hard limit is `65535` .\\n│              You can specify the `ulimit` settings for a container in a task definition.\\n│              + documentation: The `ulimit` settings to pass to the container.\\n│              Amazon ECS tasks hosted on AWS Fargate use the default resource limit values set by the operating system with the exception of the `nofile` resource limit parameter which AWS Fargate overrides. The `nofile` resource limit sets a restriction on the number of open files that a container can use. The default `nofile` soft limit is `65535` and the default hard limit is `65535` .\\n│              You can specify the `ulimit` settings for a container in a task definition.\\n├[~] service aws-eks\\n│ └ resources\\n│    └[~] resource AWS::EKS::Cluster\\n│      └ properties\\n│         └[+] BootstrapSelfManagedAddons: boolean (immutable)\\n├[~] service aws-elasticache\\n│ └ resources\\n│    ├[~] resource AWS::ElastiCache::ReplicationGroup\\n│    │ └ properties\\n│    │    └ ReplicationGroupId: (documentation changed)\\n│    ├[~] resource AWS::ElastiCache::ServerlessCache\\n│    │ └ properties\\n│    │    ├ DailySnapshotTime: (documentation changed)\\n│    │    └ SnapshotRetentionLimit: (documentation changed)\\n│    ├[~] resource AWS::ElastiCache::User\\n│    │ └ properties\\n│    │    └ Tags: (documentation changed)\\n│    └[~] resource AWS::ElastiCache::UserGroup\\n│      └ properties\\n│         └ Tags: (documentation changed)\\n├[~] service aws-emrserverless\\n│ └ resources\\n│    └[~] resource AWS::EMRServerless::Application\\n│      └ types\\n│         └[~] type WorkerConfiguration\\n│           └ properties\\n│              └[+] DiskType: string\\n├[~] service aws-gamelift\\n│ └ resources\\n│    ├[~] resource AWS::GameLift::Build\\n│    │ └ properties\\n│    │    └ OperatingSystem: (documentation changed)\\n│    └[~] resource AWS::GameLift::ContainerGroupDefinition\\n│      └ properties\\n│         └ OperatingSystem: (documentation changed)\\n├[~] service aws-glue\\n│ └ resources\\n│    ├[~] resource AWS::Glue::Connection\\n│    │ └ types\\n│    │    ├[~] type ConnectionInput\\n│    │    │ └ properties\\n│    │    │    ├ ConnectionType: (documentation changed)\\n│    │    │    ├ Name: (documentation changed)\\n│    │    │    └ PhysicalConnectionRequirements: (documentation changed)\\n│    │    └[~] type PhysicalConnectionRequirements\\n│    │      ├  - documentation: Specifies the physical requirements for a connection.\\n│    │      │  + documentation: The OAuth client app in GetConnection response.\\n│    │      └ properties\\n│    │         └ AvailabilityZone: (documentation changed)\\n│    └[~] resource AWS::Glue::Job\\n│      └ properties\\n│         └ MaintenanceWindow: (documentation changed)\\n├[~] service aws-grafana\\n│ └ resources\\n│    └[~] resource AWS::Grafana::Workspace\\n│      └ properties\\n│         ├ AuthenticationProviders: (documentation changed)\\n│         └ NotificationDestinations: (documentation changed)\\n├[~] service aws-guardduty\\n│ └ resources\\n│    ├[~] resource AWS::GuardDuty::Detector\\n│    │ ├ attributes\\n│    │ │  └ Id: (documentation changed)\\n│    │ └ types\\n│    │    ├[~] type CFNFeatureConfiguration\\n│    │    │ └ properties\\n│    │    │    └ Name: (documentation changed)\\n│    │    └[~] type TagItem\\n│    │      └ properties\\n│    │         ├ Key: (documentation changed)\\n│    │         └ Value: (documentation changed)\\n│    ├[~] resource AWS::GuardDuty::Filter\\n│    │ ├ properties\\n│    │ │  ├ DetectorId: - string (immutable)\\n│    │ │  │             + string (required, immutable)\\n│    │ │  └ Name: - string (immutable)\\n│    │ │          + string (required, immutable)\\n│    │ └ types\\n│    │    ├[~] type FindingCriteria\\n│    │    │ └ properties\\n│    │    │    └ Criterion: (documentation changed)\\n│    │    └[~] type TagItem\\n│    │      ├  - documentation: undefined\\n│    │      │  + documentation: Describes a tag.\\n│    │      └ properties\\n│    │         ├ Key: (documentation changed)\\n│    │         └ Value: (documentation changed)\\n│    ├[~] resource AWS::GuardDuty::IPSet\\n│    │ └ types\\n│    │    └[~] type TagItem\\n│    │      ├  - documentation: undefined\\n│    │      │  + documentation: Contains information about a tag.\\n│    │      └ properties\\n│    │         ├ Key: (documentation changed)\\n│    │         └ Value: (documentation changed)\\n│    ├[~] resource AWS::GuardDuty::MalwareProtectionPlan\\n│    │ ├  - documentation: Resource Type definition for AWS::GuardDuty::MalwareProtectionPlan\\n│    │ │  + documentation: Creates a new Malware Protection plan for the protected resource.\\n│    │ │  When you create a Malware Protection plan, the [AWS service terms for GuardDuty Malware Protection](https://docs.aws.amazon.com/service-terms/#87._Amazon_GuardDuty) will apply.\\n│    │ ├ properties\\n│    │ │  ├ Actions: (documentation changed)\\n│    │ │  ├ ProtectedResource: (documentation changed)\\n│    │ │  ├ Role: (documentation changed)\\n│    │ │  └ Tags: (documentation changed)\\n│    │ ├ attributes\\n│    │ │  ├ Arn: (documentation changed)\\n│    │ │  ├ MalwareProtectionPlanId: (documentation changed)\\n│    │ │  ├ Status: (documentation changed)\\n│    │ │  └ StatusReasons: (documentation changed)\\n│    │ └ types\\n│    │    ├[~] type CFNActions\\n│    │    │ ├  - documentation: undefined\\n│    │    │ │  + documentation: Specifies the action that is to be applied to the Malware Protection plan resource.\\n│    │    │ └ properties\\n│    │    │    └ Tagging: (documentation changed)\\n│    │    ├[~] type CFNProtectedResource\\n│    │    │ └  - documentation: undefined\\n│    │    │    + documentation: Information about the protected resource. Presently, `S3Bucket` is the only supported protected resource.\\n│    │    ├[~] type CFNStatusReasons\\n│    │    │ ├  - documentation: undefined\\n│    │    │ │  + documentation: Information about the status code and status details associated with the status of the Malware Protection plan.\\n│    │    │ └ properties\\n│    │    │    ├ Code: (documentation changed)\\n│    │    │    └ Message: (documentation changed)\\n│    │    ├[~] type CFNTagging\\n│    │    │ ├  - documentation: undefined\\n│    │    │ │  + documentation: Contains information about tagging status of the Malware Protection plan resource.\\n│    │    │ └ properties\\n│    │    │    └ Status: (documentation changed)\\n│    │    ├[~] type S3Bucket\\n│    │    │ └ properties\\n│    │    │    └ ObjectPrefixes: (documentation changed)\\n│    │    └[~] type TagItem\\n│    │      ├  - documentation: undefined\\n│    │      │  + documentation: Contains information about a tag.\\n│    │      └ properties\\n│    │         ├ Key: (documentation changed)\\n│    │         └ Value: (documentation changed)\\n│    ├[~] resource AWS::GuardDuty::Master\\n│    │ └ properties\\n│    │    └ InvitationId: (documentation changed)\\n│    └[~] resource AWS::GuardDuty::ThreatIntelSet\\n│      ├  - documentation: The `AWS::GuardDuty::ThreatIntelSet` resource specifies a new `ThreatIntelSet` . A `ThreatIntelSet` consists of known malicious IP addresses. GuardDuty generates findings based on the `ThreatIntelSet` when it is activated.\\n│      │  + documentation: The `AWS::GuardDuty::ThreatIntelSet` resource specifies a new `ThreatIntelSet` . A `ThreatIntelSet` consists of known malicious IP addresses. GuardDuty generates findings based on the `ThreatIntelSet` after it is activated.\\n│      ├ attributes\\n│      │  └ Id: (documentation changed)\\n│      └ types\\n│         └[~] type TagItem\\n│           ├  - documentation: undefined\\n│           │  + documentation: Contains information about a tag.\\n│           └ properties\\n│              ├ Key: (documentation changed)\\n│              └ Value: (documentation changed)\\n├[~] service aws-kinesisanalyticsv2\\n│ └ resources\\n│    └[~] resource AWS::KinesisAnalyticsV2::Application\\n│      └ types\\n│         ├[~] type ApplicationConfiguration\\n│         │ └ properties\\n│         │    └[+] ApplicationSystemRollbackConfiguration: ApplicationSystemRollbackConfiguration\\n│         └[+] type ApplicationSystemRollbackConfiguration\\n│           ├  documentation: Describes whether system initiated rollbacks are enabled for a Flink-based Kinesis Data Analytics application.\\n│           │  name: ApplicationSystemRollbackConfiguration\\n│           └ properties\\n│              └RollbackEnabled: boolean (required)\\n├[~] service aws-kinesisfirehose\\n│ └ resources\\n│    └[~] resource AWS::KinesisFirehose::DeliveryStream\\n│      └ types\\n│         ├[~] type HttpEndpointDestinationConfiguration\\n│         │ └ properties\\n│         │    └ SecretsManagerConfiguration: (documentation changed)\\n│         ├[~] type RedshiftDestinationConfiguration\\n│         │ └ properties\\n│         │    └ SecretsManagerConfiguration: (documentation changed)\\n│         ├[~] type SecretsManagerConfiguration\\n│         │ ├  - documentation: undefined\\n│         │ │  + documentation: The structure that defines how Firehose accesses the secret.\\n│         │ └ properties\\n│         │    ├ Enabled: (documentation changed)\\n│         │    ├ RoleARN: (documentation changed)\\n│         │    └ SecretARN: (documentation changed)\\n│         ├[~] type SnowflakeDestinationConfiguration\\n│         │ └ properties\\n│         │    └ SecretsManagerConfiguration: (documentation changed)\\n│         └[~] type SplunkDestinationConfiguration\\n│           └ properties\\n│              └ SecretsManagerConfiguration: (documentation changed)\\n├[~] service aws-kms\\n│ └ resources\\n│    └[~] resource AWS::KMS::Key\\n│      └ properties\\n│         ├ KeySpec: (documentation changed)\\n│         └ KeyUsage: (documentation changed)\\n├[~] service aws-networkmanager\\n│ └ resources\\n│    ├[~] resource AWS::NetworkManager::ConnectAttachment\\n│    │ └ properties\\n│    │    └ Tags: (documentation changed)\\n│    ├[~] resource AWS::NetworkManager::CoreNetwork\\n│    │ └ attributes\\n│    │    └ OwnerAccount: (documentation changed)\\n│    └[~] resource AWS::NetworkManager::SiteToSiteVpnAttachment\\n│      └ properties\\n│         └ Tags: (documentation changed)\\n├[~] service aws-omics\\n│ └ resources\\n│    └[~] resource AWS::Omics::RunGroup\\n│      └  - documentation: Creates a run group.\\n│         + documentation: You can optionally create a run group to limit the compute resources for the runs that you add to the group.\\n├[~] service aws-opsworkscm\\n│ └ resources\\n│    └[~] resource AWS::OpsWorksCM::Server\\n│      └ properties\\n│         └ ServerName: (documentation changed)\\n├[~] service aws-rds\\n│ └ resources\\n│    ├[~] resource AWS::RDS::DBCluster\\n│    │ └ properties\\n│    │    ├[+] EnableLocalWriteForwarding: boolean\\n│    │    └[+] EngineLifecycleSupport: string\\n│    ├[~] resource AWS::RDS::DBInstance\\n│    │ └ properties\\n│    │    └[+] EngineLifecycleSupport: string\\n│    └[~] resource AWS::RDS::GlobalCluster\\n│      └ properties\\n│         └[+] EngineLifecycleSupport: string\\n├[~] service aws-redshift\\n│ └ resources\\n│    ├[~] resource AWS::Redshift::Cluster\\n│    │ └ properties\\n│    │    ├ NodeType: (documentation changed)\\n│    │    └ Port: (documentation changed)\\n│    └[~] resource AWS::Redshift::ScheduledAction\\n│      └ properties\\n│         └ TargetAction: (documentation changed)\\n├[~] service aws-s3\\n│ └ resources\\n│    └[~] resource AWS::S3::Bucket\\n│      └ types\\n│         ├[~] type EncryptionConfiguration\\n│         │ └  - documentation: Specifies encryption-related information for an Amazon S3 bucket that is a destination for replicated objects.\\n│         │    + documentation: Specifies encryption-related information for an Amazon S3 bucket that is a destination for replicated objects.\\n│         │    > If you're specifying a customer managed KMS key, we recommend using a fully qualified KMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the requester’s account. This behavior can result in data that's encrypted with a KMS key that belongs to the requester, and not the bucket owner.\\n│         ├[~] type PartitionedPrefix\\n│         │ └ properties\\n│         │    └ PartitionDateSource: (documentation changed)\\n│         ├[~] type ServerSideEncryptionByDefault\\n│         │ └  - documentation: Describes the default server-side encryption to apply to new objects in the bucket. If a PUT Object request doesn't specify any server-side encryption, this default encryption will be applied. If you don't specify a customer managed key at configuration, Amazon S3 automatically creates an AWS KMS key in your AWS account the first time that you add an object encrypted with SSE-KMS to a bucket. By default, Amazon S3 uses this KMS key for SSE-KMS. For more information, see [PUT Bucket encryption](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTencryption.html) in the *Amazon S3 API Reference* .\\n│         │    + documentation: Describes the default server-side encryption to apply to new objects in the bucket. If a PUT Object request doesn't specify any server-side encryption, this default encryption will be applied. If you don't specify a customer managed key at configuration, Amazon S3 automatically creates an AWS KMS key in your AWS account the first time that you add an object encrypted with SSE-KMS to a bucket. By default, Amazon S3 uses this KMS key for SSE-KMS. For more information, see [PUT Bucket encryption](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTencryption.html) in the *Amazon S3 API Reference* .\\n│         │    > If you're specifying a customer managed KMS key, we recommend using a fully qualified KMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the requester’s account. This behavior can result in data that's encrypted with a KMS key that belongs to the requester, and not the bucket owner.\\n│         └[~] type ServerSideEncryptionRule\\n│           └  - documentation: Specifies the default server-side encryption configuration.\\n│              + documentation: Specifies the default server-side encryption configuration.\\n│              > If you're specifying a customer managed KMS key, we recommend using a fully qualified KMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the requester’s account. This behavior can result in data that's encrypted with a KMS key that belongs to the requester, and not the bucket owner.\\n├[~] service aws-servicediscovery\\n│ └ resources\\n│    └[~] resource AWS::ServiceDiscovery::Instance\\n│      └ properties\\n│         └ InstanceId: (documentation changed)\\n├[~] service aws-ses\\n│ └ resources\\n│    └[~] resource AWS::SES::ConfigurationSetEventDestination\\n│      └ types\\n│         ├[+] type EventBridgeDestination\\n│         │ ├  documentation: An object that contains Event bus ARN associated with the event bridge destination.\\n│         │ │  name: EventBridgeDestination\\n│         │ └ properties\\n│         │    └EventBusArn: string (required)\\n│         └[~] type EventDestination\\n│           └ properties\\n│              └[+] EventBridgeDestination: EventBridgeDestination\\n├[~] service aws-signer\\n│ └ resources\\n│    └[~] resource AWS::Signer::SigningProfile\\n│      └ properties\\n│         └[+] ProfileName: string (immutable)\\n├[~] service aws-sqs\\n│ └ resources\\n│    └[~] resource AWS::SQS::Queue\\n│      └ properties\\n│         └ RedrivePolicy: (documentation changed)\\n├[~] service aws-ssm\\n│ └ resources\\n│    └[~] resource AWS::SSM::ResourceDataSync\\n│      └ properties\\n│         └ SyncName: (documentation changed)\\n├[~] service aws-verifiedpermissions\\n│ └ resources\\n│    └[~] resource AWS::VerifiedPermissions::IdentitySource\\n│      └ types\\n│         ├[~] type IdentitySourceConfiguration\\n│         │ └ properties\\n│         │    ├ CognitoUserPoolConfiguration: - CognitoUserPoolConfiguration (required)\\n│         │    │                               + CognitoUserPoolConfiguration\\n│         │    └[+] OpenIdConnectConfiguration: OpenIdConnectConfiguration\\n│         ├[+] type OpenIdConnectAccessTokenConfiguration\\n│         │ ├  documentation: The configuration of an OpenID Connect (OIDC) identity source for handling access token claims. Contains the claim that you want to identify as the principal in an authorization request, and the values of the `aud` claim, or audiences, that you want to accept.\\n│         │ │  This data type is part of a [OpenIdConnectTokenSelection](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_OpenIdConnectTokenSelection.html) structure, which is a parameter of [CreateIdentitySource](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_CreateIdentitySource.html) .\\n│         │ │  name: OpenIdConnectAccessTokenConfiguration\\n│         │ └ properties\\n│         │    ├PrincipalIdClaim: string (default=\\\"sub\\\")\\n│         │    └Audiences: Array<string>\\n│         ├[+] type OpenIdConnectConfiguration\\n│         │ ├  documentation: Contains configuration details of an OpenID Connect (OIDC) identity provider, or identity source, that Verified Permissions can use to generate entities from authenticated identities. It specifies the issuer URL, token type that you want to use, and policy store entity details.\\n│         │ │  This data type is part of a [Configuration](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_Configuration.html) structure, which is a parameter to [CreateIdentitySource](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_CreateIdentitySource.html) .\\n│         │ │  name: OpenIdConnectConfiguration\\n│         │ └ properties\\n│         │    ├Issuer: string (required)\\n│         │    ├EntityIdPrefix: string\\n│         │    ├GroupConfiguration: OpenIdConnectGroupConfiguration\\n│         │    └TokenSelection: OpenIdConnectTokenSelection (required)\\n│         ├[+] type OpenIdConnectGroupConfiguration\\n│         │ ├  documentation: The claim in OIDC identity provider tokens that indicates a user's group membership, and the entity type that you want to map it to. For example, this object can map the contents of a `groups` claim to `MyCorp::UserGroup` .\\n│         │ │  This data type is part of a [OpenIdConnectConfiguration](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_OpenIdConnectConfiguration.html) structure, which is a parameter of [CreateIdentitySource](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_CreateIdentitySource.html) .\\n│         │ │  name: OpenIdConnectGroupConfiguration\\n│         │ └ properties\\n│         │    ├GroupClaim: string (required)\\n│         │    └GroupEntityType: string (required)\\n│         ├[+] type OpenIdConnectIdentityTokenConfiguration\\n│         │ ├  documentation: The configuration of an OpenID Connect (OIDC) identity source for handling identity (ID) token claims. Contains the claim that you want to identify as the principal in an authorization request, and the values of the `aud` claim, or audiences, that you want to accept.\\n│         │ │  This data type is part of a [OpenIdConnectTokenSelection](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_OpenIdConnectTokenSelection.html) structure, which is a parameter of [CreateIdentitySource](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_CreateIdentitySource.html) .\\n│         │ │  name: OpenIdConnectIdentityTokenConfiguration\\n│         │ └ properties\\n│         │    ├PrincipalIdClaim: string (default=\\\"sub\\\")\\n│         │    └ClientIds: Array<string>\\n│         └[+] type OpenIdConnectTokenSelection\\n│           ├  documentation: The token type that you want to process from your OIDC identity provider. Your policy store can process either identity (ID) or access tokens from a given OIDC identity source.\\n│           │  This data type is part of a [OpenIdConnectConfiguration](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_OpenIdConnectConfiguration.html) structure, which is a parameter of [CreateIdentitySource](https://docs.aws.amazon.com/verifiedpermissions/latest/apireference/API_CreateIdentitySource.html) .\\n│           │  name: OpenIdConnectTokenSelection\\n│           └ properties\\n│              ├AccessTokenOnly: OpenIdConnectAccessTokenConfiguration\\n│              └IdentityTokenOnly: OpenIdConnectIdentityTokenConfiguration\\n├[~] service aws-workspaces\\n│ └ resources\\n│    └[+] resource AWS::WorkSpaces::WorkspacesPool\\n│      ├  name: WorkspacesPool\\n│      │  cloudFormationType: AWS::WorkSpaces::WorkspacesPool\\n│      │  documentation: Resource Type definition for AWS::WorkSpaces::WorkspacesPool\\n│      │  tagInformation: {\\\"tagPropertyName\\\":\\\"Tags\\\",\\\"variant\\\":\\\"standard\\\"}\\n│      ├ properties\\n│      │  ├Capacity: Capacity (required)\\n│      │  ├PoolName: string (required, immutable)\\n│      │  ├Description: string\\n│      │  ├BundleId: string (required)\\n│      │  ├DirectoryId: string (required)\\n│      │  ├ApplicationSettings: ApplicationSettings\\n│      │  ├TimeoutSettings: TimeoutSettings\\n│      │  └Tags: Array<tag>\\n│      ├ attributes\\n│      │  ├PoolId: string\\n│      │  ├PoolArn: string\\n│      │  └CreatedAt: string\\n│      └ types\\n│         ├type Capacity\\n│         │├  name: Capacity\\n│         │└ properties\\n│         │   └DesiredUserSessions: integer (required)\\n│         ├type ApplicationSettings\\n│         │├  name: ApplicationSettings\\n│         │└ properties\\n│         │   ├Status: string (required)\\n│         │   └SettingsGroup: string\\n│         └type TimeoutSettings\\n│          ├  name: TimeoutSettings\\n│          └ properties\\n│             ├DisconnectTimeoutInSeconds: integer\\n│             ├IdleDisconnectTimeoutInSeconds: integer\\n│             └MaxUserDurationInSeconds: integer\\n└[~] service aws-workspacesweb\\n  └ resources\\n     └[~] resource AWS::WorkSpacesWeb::IpAccessSettings\\n       └ properties\\n          └ Tags: (documentation changed)\\n```\",\"distinct\":true,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/4ceecedd3d91465b29db21b10239937b99b5f79c\"},{\"sha\":\"7f5ce4bfe94b19efe6c0c8aa0ec850cdfc4b8ebb\",\"author\":{\"email\":\"78883180+xazhao@users.noreply.github.com\",\"name\":\"Xia Zhao\"},\"message\":\"fix(lambda-nodejs): breaking change in esbuild causes import module error (#30726)\\n\\n### Issue # (if applicable)\\n\\nCloses #30717.\\n\\n### Reason for this change\\n\\nesbuild introduced a breaking change in v0.22 which caused the build error in `aws-lambda-nodejs` module.\\n\\n### Description of changes\\n\\nPin the esbuild version to 0.21 in Dockerfile\\n\\n### Description of how you validated changes\\n\\n\\n\\n### Checklist\\n- [x] My code adheres to the [CONTRIBUTING GUIDE](https://github.com/aws/aws-cdk/blob/main/CONTRIBUTING.md) and [DESIGN GUIDELINES](https://github.com/aws/aws-cdk/blob/main/docs/DESIGN_GUIDELINES.md)\\n\\n----\\n\\n*By submitting this pull request, I confirm that my contribution is made under the terms of the Apache-2.0 license*\",\"distinct\":true,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/7f5ce4bfe94b19efe6c0c8aa0ec850cdfc4b8ebb\"},{\"sha\":\"06c14b16d04353e9e108b58edc1450d018c24b12\",\"author\":{\"email\":\"78883180+xazhao@users.noreply.github.com\",\"name\":\"Xia Zhao\"},\"message\":\"fix(lambda-nodejs): breaking change in esbuild causes import module error (#30726)\\n\\n### Issue # (if applicable)\\n\\nCloses #30717.\\n\\n### Reason for this change\\n\\nesbuild introduced a breaking change in v0.22 which caused the build error in `aws-lambda-nodejs` module.\\n\\n### Description of changes\\n\\nPin the esbuild version to 0.21 in Dockerfile\\n\\n### Description of how you validated changes\\n\\n\\n\\n### Checklist\\n- [x] My code adheres to the [CONTRIBUTING GUIDE](https://github.com/aws/aws-cdk/blob/main/CONTRIBUTING.md) and [DESIGN GUIDELINES](https://github.com/aws/aws-cdk/blob/main/docs/DESIGN_GUIDELINES.md)\\n\\n----\\n\\n*By submitting this pull request, I confirm that my contribution is made under the terms of the Apache-2.0 license*\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/06c14b16d04353e9e108b58edc1450d018c24b12\"},{\"sha\":\"b8bd95bb0ef4c589091a00f0e53b107150b64042\",\"author\":{\"email\":\"xazhao@amazon.com\",\"name\":\"Xia Zhao\"},\"message\":\"chore(release): 2.147.3\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/b8bd95bb0ef4c589091a00f0e53b107150b64042\"},{\"sha\":\"32f0fdbbeccfd9b9824c02a94d83c249d0a06ab2\",\"author\":{\"email\":\"37929162+mergify[bot]@users.noreply.github.com\",\"name\":\"mergify[bot]\"},\"message\":\"chore(release): v2.147.3 (#30729)\\n\\nSee CHANGELOG\",\"distinct\":false,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/32f0fdbbeccfd9b9824c02a94d83c249d0a06ab2\"},{\"sha\":\"894745187fbd2dcc03b0b7ac04eb0870200c74e1\",\"author\":{\"email\":\"37929162+mergify[bot]@users.noreply.github.com\",\"name\":\"mergify[bot]\"},\"message\":\"Merge branch 'main' into merge-back/2.147.3\",\"distinct\":true,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/894745187fbd2dcc03b0b7ac04eb0870200c74e1\"},{\"sha\":\"84fc01f479e598e2704721be23c6f038fe25d62b\",\"author\":{\"email\":\"37929162+mergify[bot]@users.noreply.github.com\",\"name\":\"mergify[bot]\"},\"message\":\"chore(merge-back): 2.147.3 (#30730)\\n\\nSee [CHANGELOG](https://github.com/aws/aws-cdk/blob/merge-back/2.147.3/CHANGELOG.md)\",\"distinct\":true,\"url\":\"https://api.github.com/repos/TheRealAmazonKendra/aws-cdk/commits/84fc01f479e598e2704721be23c6f038fe25d62b\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531561\",\"type\":\"DeleteEvent\",\"actor\":{\"id\":68524199,\"login\":\"hwany7seo\",\"display_login\":\"hwany7seo\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/hwany7seo\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/68524199?\"},\"repo\":{\"id\":297868006,\"name\":\"hwany7seo/cubrid-migration\",\"url\":\"https://api.github.com/repos/hwany7seo/cubrid-migration\"},\"payload\":{\"ref\":\"copyright_back\",\"ref_type\":\"branch\",\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:09Z\"},{\"id\":\"39785531538\",\"type\":\"CreateEvent\",\"actor\":{\"id\":173746182,\"login\":\"JavierCaroLazo\",\"display_login\":\"JavierCaroLazo\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/JavierCaroLazo\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/173746182?\"},\"repo\":{\"id\":822880010,\"name\":\"JavierCaroLazo/final\",\"url\":\"https://api.github.com/repos/JavierCaroLazo/final\"},\"payload\":{\"ref\":\"main\",\"ref_type\":\"branch\",\"master_branch\":\"main\",\"description\":null,\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531537\",\"type\":\"DeleteEvent\",\"actor\":{\"id\":29139614,\"login\":\"renovate[bot]\",\"display_login\":\"renovate\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/renovate[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/29139614?\"},\"repo\":{\"id\":258987779,\"name\":\"prabirshrestha/rblog\",\"url\":\"https://api.github.com/repos/prabirshrestha/rblog\"},\"payload\":{\"ref\":\"renovate/mime_guess-2.x-lockfile\",\"ref_type\":\"branch\",\"pusher_type\":\"user\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531524\",\"type\":\"WatchEvent\",\"actor\":{\"id\":174400079,\"login\":\"z6ncai\",\"display_login\":\"z6ncai\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/z6ncai\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/174400079?\"},\"repo\":{\"id\":423888812,\"name\":\"wavestone-cdt/EDRSandblast\",\"url\":\"https://api.github.com/repos/wavestone-cdt/EDRSandblast\"},\"payload\":{\"action\":\"started\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531507\",\"type\":\"WatchEvent\",\"actor\":{\"id\":1639394,\"login\":\"hadesh\",\"display_login\":\"hadesh\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/hadesh\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/1639394?\"},\"repo\":{\"id\":29788130,\"name\":\"commonmark/commonmark.js\",\"url\":\"https://api.github.com/repos/commonmark/commonmark.js\"},\"payload\":{\"action\":\"started\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\",\"org\":{\"id\":8661225,\"login\":\"commonmark\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/commonmark\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/8661225?\"}},{\"id\":\"39785531468\",\"type\":\"PushEvent\",\"actor\":{\"id\":158424993,\"login\":\"strozoid\",\"display_login\":\"strozoid\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/strozoid\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/158424993?\"},\"repo\":{\"id\":814075105,\"name\":\"strozoid/Ecchi\",\"url\":\"https://api.github.com/repos/strozoid/Ecchi\"},\"payload\":{\"repository_id\":814075105,\"push_id\":19131669269,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"60bcd1c6f0ae2b1a273f61a073f2f68cdad64159\",\"before\":\"8ce375531dff852267c1b5c7fd0bb7a75810a877\",\"commits\":[{\"sha\":\"60bcd1c6f0ae2b1a273f61a073f2f68cdad64159\",\"author\":{\"email\":\"thefrost329@gmail.com\",\"name\":\"strozoid\"},\"message\":\"Commit Ecchi\",\"distinct\":true,\"url\":\"https://api.github.com/repos/strozoid/Ecchi/commits/60bcd1c6f0ae2b1a273f61a073f2f68cdad64159\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531505\",\"type\":\"WatchEvent\",\"actor\":{\"id\":552923,\"login\":\"rwnobrega\",\"display_login\":\"rwnobrega\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/rwnobrega\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/552923?\"},\"repo\":{\"id\":19205896,\"name\":\"restic/restic\",\"url\":\"https://api.github.com/repos/restic/restic\"},\"payload\":{\"action\":\"started\"},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\",\"org\":{\"id\":10073512,\"login\":\"restic\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/restic\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/10073512?\"}},{\"id\":\"39785531451\",\"type\":\"PushEvent\",\"actor\":{\"id\":143675534,\"login\":\"Pepeganga14\",\"display_login\":\"Pepeganga14\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/Pepeganga14\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/143675534?\"},\"repo\":{\"id\":822338028,\"name\":\"Pepeganga14/msp\",\"url\":\"https://api.github.com/repos/Pepeganga14/msp\"},\"payload\":{\"repository_id\":822338028,\"push_id\":19131669256,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"10ae5a610e1cd1a16aad20f2622b6c9a0971ff99\",\"before\":\"5959b3359c72b2628b9167cfc1f777ccd7f222f3\",\"commits\":[{\"sha\":\"10ae5a610e1cd1a16aad20f2622b6c9a0971ff99\",\"author\":{\"email\":\"143675534+Pepeganga14@users.noreply.github.com\",\"name\":\"Pepeganga14\"},\"message\":\"Mundo guardado 2024-07-02\",\"distinct\":true,\"url\":\"https://api.github.com/repos/Pepeganga14/msp/commits/10ae5a610e1cd1a16aad20f2622b6c9a0971ff99\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531461\",\"type\":\"PushEvent\",\"actor\":{\"id\":102790989,\"login\":\"kpnsec\",\"display_login\":\"kpnsec\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/kpnsec\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/102790989?\"},\"repo\":{\"id\":713192428,\"name\":\"kpnsec/iplist\",\"url\":\"https://api.github.com/repos/kpnsec/iplist\"},\"payload\":{\"repository_id\":713192428,\"push_id\":19131669263,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"b6ceac934594c64d545e2b5980dd8dfeaa9819f0\",\"before\":\"c5f8459dcc344c4f5a2ec2033823a974da5305b7\",\"commits\":[{\"sha\":\"b6ceac934594c64d545e2b5980dd8dfeaa9819f0\",\"author\":{\"email\":\"102790989+kpnsec@users.noreply.github.com\",\"name\":\"kpnsec\"},\"message\":\"message\",\"distinct\":true,\"url\":\"https://api.github.com/repos/kpnsec/iplist/commits/b6ceac934594c64d545e2b5980dd8dfeaa9819f0\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531490\",\"type\":\"PushEvent\",\"actor\":{\"id\":173744365,\"login\":\"lia006\",\"display_login\":\"lia006\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/lia006\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/173744365?\"},\"repo\":{\"id\":822336711,\"name\":\"lia006/projectrepo\",\"url\":\"https://api.github.com/repos/lia006/projectrepo\"},\"payload\":{\"repository_id\":822336711,\"push_id\":19131669279,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"500897f426ca88c1cbb92c0a480c32b1a7373814\",\"before\":\"869ac65516f622113a4cb5e0a520c37cdc55dbd9\",\"commits\":[{\"sha\":\"500897f426ca88c1cbb92c0a480c32b1a7373814\",\"author\":{\"email\":\"123gpfla@naver.com\",\"name\":\"lia006\"},\"message\":\"10000.css\",\"distinct\":true,\"url\":\"https://api.github.com/repos/lia006/projectrepo/commits/500897f426ca88c1cbb92c0a480c32b1a7373814\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531448\",\"type\":\"PushEvent\",\"actor\":{\"id\":25118482,\"login\":\"sircfenner\",\"display_login\":\"sircfenner\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/sircfenner\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/25118482?\"},\"repo\":{\"id\":822877341,\"name\":\"sircfenner/AutoImport\",\"url\":\"https://api.github.com/repos/sircfenner/AutoImport\"},\"payload\":{\"repository_id\":822877341,\"push_id\":19131669248,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"2e68a76a4b751d5c79e4197234b9f62109ba26be\",\"before\":\"5e640761cb16231a65d920899d6111ceed141893\",\"commits\":[{\"sha\":\"2e68a76a4b751d5c79e4197234b9f62109ba26be\",\"author\":{\"email\":\"sircfenner@users.noreply.github.com\",\"name\":\"sircfenner\"},\"message\":\"Update README\\n\\n- Installation instructions\\r\\n- Demo video\\r\\n- Note about comment directives\",\"distinct\":true,\"url\":\"https://api.github.com/repos/sircfenner/AutoImport/commits/2e68a76a4b751d5c79e4197234b9f62109ba26be\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531479\",\"type\":\"PushEvent\",\"actor\":{\"id\":41898282,\"login\":\"github-actions[bot]\",\"display_login\":\"github-actions\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/github-actions[bot]\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/41898282?\"},\"repo\":{\"id\":738111702,\"name\":\"McDic/BlogV2\",\"url\":\"https://api.github.com/repos/McDic/BlogV2\"},\"payload\":{\"repository_id\":738111702,\"push_id\":19131669280,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/deploy\",\"head\":\"99275268fd4a49afbfcd34d2c290b97e6bde29c4\",\"before\":\"125fbee2d376d372d53684e18c7af9b9d3a9660f\",\"commits\":[{\"sha\":\"99275268fd4a49afbfcd34d2c290b97e6bde29c4\",\"author\":{\"email\":\"41898282+github-actions[bot]@users.noreply.github.com\",\"name\":\"github-actions[bot]\"},\"message\":\"Deployed 215ef31 with MkDocs version: 1.6.0\",\"distinct\":true,\"url\":\"https://api.github.com/repos/McDic/BlogV2/commits/99275268fd4a49afbfcd34d2c290b97e6bde29c4\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531487\",\"type\":\"PushEvent\",\"actor\":{\"id\":36560983,\"login\":\"Alexecz\",\"display_login\":\"Alexecz\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/Alexecz\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/36560983?\"},\"repo\":{\"id\":406019422,\"name\":\"Alexecz/mimotion\",\"url\":\"https://api.github.com/repos/Alexecz/mimotion\"},\"payload\":{\"repository_id\":406019422,\"push_id\":19131669276,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/master\",\"head\":\"b5dc6ae514b59e6df96d8cb5825e60842ab76ac1\",\"before\":\"44cbcf8fba84eaa0063280d90f6a0df7d2137482\",\"commits\":[{\"sha\":\"b5dc6ae514b59e6df96d8cb5825e60842ab76ac1\",\"author\":{\"email\":\"github-actions@github.com\",\"name\":\"github-actions\"},\"message\":\"random cron.\",\"distinct\":true,\"url\":\"https://api.github.com/repos/Alexecz/mimotion/commits/b5dc6ae514b59e6df96d8cb5825e60842ab76ac1\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531471\",\"type\":\"PushEvent\",\"actor\":{\"id\":75749677,\"login\":\"PotatoesSkill\",\"display_login\":\"PotatoesSkill\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/PotatoesSkill\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/75749677?\"},\"repo\":{\"id\":729539212,\"name\":\"PotatoesSkill/zelf\",\"url\":\"https://api.github.com/repos/PotatoesSkill/zelf\"},\"payload\":{\"repository_id\":729539212,\"push_id\":19131669268,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"7a1536381ab746b43313fb663d1adf5698a2f2c7\",\"before\":\"fa6fdd656de314655e27bb04a2b387a20c11ecd4\",\"commits\":[{\"sha\":\"7a1536381ab746b43313fb663d1adf5698a2f2c7\",\"author\":{\"email\":\"75749677+PotatoesSkill@users.noreply.github.com\",\"name\":\"PotatoesSkill\"},\"message\":\"a\",\"distinct\":true,\"url\":\"https://api.github.com/repos/PotatoesSkill/zelf/commits/7a1536381ab746b43313fb663d1adf5698a2f2c7\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531475\",\"type\":\"PushEvent\",\"actor\":{\"id\":88896503,\"login\":\"Proking4444\",\"display_login\":\"Proking4444\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/Proking4444\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/88896503?\"},\"repo\":{\"id\":742933611,\"name\":\"Proking4444/KingBot\",\"url\":\"https://api.github.com/repos/Proking4444/KingBot\"},\"payload\":{\"repository_id\":742933611,\"push_id\":19131669255,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"26ff0854261e885db5fa836c704cdaaadaf041b9\",\"before\":\"0ef731a7c930c81ce87a4d53e97e695f2152d444\",\"commits\":[{\"sha\":\"26ff0854261e885db5fa836c704cdaaadaf041b9\",\"author\":{\"email\":\"ari.basil.khan@gmail.com\",\"name\":\"Ari\"},\"message\":\"170th Commit.\",\"distinct\":true,\"url\":\"https://api.github.com/repos/Proking4444/KingBot/commits/26ff0854261e885db5fa836c704cdaaadaf041b9\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\"},{\"id\":\"39785531485\",\"type\":\"PushEvent\",\"actor\":{\"id\":73035340,\"login\":\"Zekiah-A\",\"display_login\":\"Zekiah-A\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/Zekiah-A\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/73035340?\"},\"repo\":{\"id\":660685554,\"name\":\"rplacetk/canvas1\",\"url\":\"https://api.github.com/repos/rplacetk/canvas1\"},\"payload\":{\"repository_id\":660685554,\"push_id\":19131669282,\"size\":1,\"distinct_size\":1,\"ref\":\"refs/heads/main\",\"head\":\"b94be51a0a8ac8625d9d5ecf6e82d046648fae92\",\"before\":\"79400edf044363773695fab6d327a6b8b31f57d6\",\"commits\":[{\"sha\":\"b94be51a0a8ac8625d9d5ecf6e82d046648fae92\",\"author\":{\"email\":\"admin@rplace.live\",\"name\":\"nebulus\"},\"message\":\"Canvas backup\",\"distinct\":true,\"url\":\"https://api.github.com/repos/rplacetk/canvas1/commits/b94be51a0a8ac8625d9d5ecf6e82d046648fae92\"}]},\"public\":true,\"created_at\":\"2024-07-02T02:37:08Z\",\"org\":{\"id\":138234595,\"login\":\"rplacetk\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/orgs/rplacetk\",\"avatar_url\":\"https://avatars.githubusercontent.com/u/138234595?\"}}]\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://api.github.com/events')\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26133657-5c3b-49d0-aa46-b809f73847cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    'query': '동아일보'\n",
    "}\n",
    "r = requests.get('https://m.search.naver.com/search.naver', params=payload)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ba4c83-3697-42a3-be55-96cb62be08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    'q': 'channela'\n",
    "}\n",
    "r = requests.get('https://www.google.com/search', params=payload)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c612a8d-c0d9-48dd-a2ab-59f867a11b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'totSellamnt': 111998191000, 'returnValue': 'success', 'drwNoDate': '2024-06-29', 'firstWinamnt': 2386382421, 'drwtNo6': 40, 'drwtNo4': 11, 'firstPrzwnerCo': 11, 'drwtNo5': 37, 'bnusNo': 7, 'firstAccumamnt': 26250206631, 'drwNo': 1126, 'drwtNo2': 5, 'drwtNo3': 9, 'drwtNo1': 4}\n"
     ]
    }
   ],
   "source": [
    "payload ={\n",
    "    'method' : 'getLottoNumber',\n",
    "    'drwNo' : 1126,\n",
    "}\n",
    "r = requests.get('https://www.dhlottery.co.kr/common.do', params=payload)\n",
    "#print(r.text\n",
    "print(r.json())\n",
    "lotto_dict = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb977e83-ef07-42d2-80db-754262ab0bc2",
   "metadata": {},
   "source": [
    "## 구현해야 할 내용\n",
    "-  requests를 통해서 이번주 당첨번호를 가져 온 후 list에 넣어서 출력하기 \n",
    "- 5회차 번호를 sample 함수를 이용해서 번호 6개 출력\n",
    "- 정답 리스트랑 dict안에 있는 회차 번호랑 비교해서 1-5등, 꽝여부 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d4b40d6-83bb-46dc-a953-793bfb6c09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번주 당첨번호 : [4, 5, 9, 11, 37, 40], BN: 7\n",
      "{'1회차': [3, 25, 31, 6, 24, 43], '2회차': [18, 10, 17, 32, 41, 24], '3회차': [22, 34, 32, 15, 3, 27], '4회차': [13, 4, 8, 42, 3, 15], '5회차': [11, 4, 12, 20, 8, 7]}\n",
      "꽝\n",
      "꽝\n",
      "꽝\n",
      "꽝\n",
      "꽝\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "payload ={\n",
    "    'method' : 'getLottoNumber',\n",
    "    'drwNo' : 1126,\n",
    "}\n",
    "r = requests.get('https://www.dhlottery.co.kr/common.do', params=payload)\n",
    "\n",
    "lotto_dict = r.json()\n",
    "\n",
    "numbers = list(range(1,46))\n",
    "buy_dict = {}\n",
    "for i in range(1,6):\n",
    "    buy_dict[f'{i}회차'] = random.sample(numbers, 6)\n",
    "    \n",
    "correct_list = []\n",
    "bonus = lotto_dict['bnusNo']\n",
    "for i in range(1,7):\n",
    "    correct_list.append(lotto_dict[f'drwtNo{i}'])\n",
    "print(f'이번주 당첨번호 : {correct_list}, BN: {bonus}')\n",
    "print(buy_dict)\n",
    "\n",
    "for key, value in buy_dict.items():\n",
    "    cnt = 0\n",
    "    for i in value:\n",
    "        if i not in correct_list:\n",
    "            cnt += 1\n",
    "        #만약에 cnt = 1이면 나머지 숫자가 bonus 점수인지 비교하는 코드 \n",
    "        # cnt 수에 따른 등수 출력\n",
    "    if cnt == 0:\n",
    "        print(\"1등\")\n",
    "    elif cnt == 1:\n",
    "        if bonus in value:\n",
    "            print(\"2등\")\n",
    "        else:\n",
    "            print(\"3등\")\n",
    "    elif cnt == 2:\n",
    "        print(\"4등\")\n",
    "    elif cnt == 3:\n",
    "        print(\"5등\")\n",
    "    else:\n",
    "        print(\"꽝\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1b4527dc-348f-4e7e-a404-fcbe95e49e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번주 당첨번호 : [4, 5, 9, 11, 37, 40], BN: 7\n",
      "{'1회차': [4, 5, 9, 11, 37, 6], '2회차': [4, 5, 9, 11, 37, 40], '3회차': [4, 5, 9, 11, 37, 7], '4회차': [4, 5, 7, 9, 10, 12]}\n",
      "[4, 5, 9, 11, 37, 6]\n",
      "3등\n",
      "[4, 5, 9, 11, 37, 40]\n",
      "1등\n",
      "[4, 5, 9, 11, 37, 7]\n",
      "2등\n",
      "[4, 5, 7, 9, 10, 12]\n",
      "5등\n"
     ]
    }
   ],
   "source": [
    "#검증용 코드 \n",
    "import random\n",
    "payload ={\n",
    "    'method' : 'getLottoNumber',\n",
    "    'drwNo' : 1126,\n",
    "}\n",
    "r = requests.get('https://www.dhlottery.co.kr/common.do', params=payload)\n",
    "\n",
    "lotto_dict = r.json()\n",
    "\n",
    "numbers = list(range(1,46))\n",
    "buy_dict = {}\n",
    "for i in range(1,6):\n",
    "    buy_dict[f'{i}회차'] = random.sample(numbers, 6)\n",
    "    \n",
    "correct_list = []\n",
    "bonus = lotto_dict['bnusNo']\n",
    "\n",
    "buy_dict = {'1회차' : [4, 5, 9, 11, 37, 6 ], '2회차' : [4, 5, 9, 11, 37, 40], '3회차' : [4, 5, 9, 11, 37, 7 ], '4회차' : [4, 5, 7, 9, 10, 12]}\n",
    "\n",
    "for i in range(1,7):\n",
    "    correct_list.append(lotto_dict[f'drwtNo{i}'])\n",
    "print(f'이번주 당첨번호 : {correct_list}, BN: {bonus}')\n",
    "print(buy_dict)\n",
    "for key, value in buy_dict.items():\n",
    "    print(value)\n",
    "    cnt = 0\n",
    "    for i in value:\n",
    "        if i not in correct_list:\n",
    "            cnt += 1\n",
    "        #만약에 cnt = 1이면 나머지 숫자가 bonus 점수인지 비교하는 코드 \n",
    "        # cnt 수에 따른 등수 출력\n",
    "    if cnt == 0:\n",
    "        print(\"1등\")\n",
    "    elif cnt == 1:\n",
    "        if bonus in value:\n",
    "            print(\"2등\")\n",
    "        else:\n",
    "            print(\"3등\")\n",
    "    elif cnt == 2:\n",
    "        print(\"4등\")\n",
    "    elif cnt == 3:\n",
    "        print(\"5등\")\n",
    "    else:\n",
    "        print(\"꽝\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5523f-b2a8-4e96-a9dc-2470a21ffce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
